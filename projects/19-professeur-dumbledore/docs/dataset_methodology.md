# ğŸ“Š MÃ©thodologie de CrÃ©ation du Dataset

## ğŸ¯ Objectif

CrÃ©er un dataset audio de qualitÃ© pour entraÃ®ner un modÃ¨le de reconnaissance vocale capable d'identifier 10 formules magiques de l'univers Harry Potter.

## ğŸ“‹ Formules cibles

1. **Expelliarmus** - SortilÃ¨ge de dÃ©sarmement
2. **Lumos** - SortilÃ¨ge de lumiÃ¨re
3. **Nox** - Ã‰teint la lumiÃ¨re
4. **Wingardium Leviosa** - SortilÃ¨ge de lÃ©vitation
5. **Alohomora** - SortilÃ¨ge d'ouverture
6. **Expecto Patronum** - Invoque un patronus
7. **Avada Kedavra** - Sort impardonnable
8. **Stupefy** - SortilÃ¨ge de stupÃ©fixion
9. **Protego** - Bouclier protecteur
10. **Accio** - SortilÃ¨ge d'attraction

## ğŸ”¬ Approches de collecte de donnÃ©es

### 1. SynthÃ¨se vocale (TTS) - Approche principale

#### Services recommandÃ©s

**Google Text-to-Speech (gTTS)**
```python
from gtts import gTTS
import os

spells = ["expelliarmus", "lumos", "nox", ...]

for spell in spells:
    for lang in ['en', 'en-uk', 'en-us', 'en-au']:
        tts = gTTS(spell, lang=lang)
        tts.save(f"data/raw/{spell}_{lang}.mp3")
```

**Amazon Polly** (qualitÃ© supÃ©rieure)
```python
import boto3

polly = boto3.client('polly')
voices = ['Matthew', 'Joanna', 'Brian', 'Amy', 'Emma']

for spell in spells:
    for voice in voices:
        response = polly.synthesize_speech(
            Text=spell,
            OutputFormat='mp3',
            VoiceId=voice
        )
        # Sauvegarde...
```

**ElevenLabs** (meilleure qualitÃ©, payant)
- Voix naturelles et expressives
- ContrÃ´le de l'intonation
- API simple Ã  utiliser

#### Avantages du TTS
âœ… GÃ©nÃ©ration rapide de nombreux Ã©chantillons
âœ… ContrÃ´le total sur la qualitÃ©
âœ… Pas de bruit de fond
âœ… CohÃ©rence entre les Ã©chantillons

#### InconvÃ©nients
âŒ Peut manquer de naturel
âŒ Intonation parfois robotique
âŒ Variations limitÃ©es

### 2. Enregistrements humains - Approche idÃ©ale

#### Protocole d'enregistrement

**MatÃ©riel requis:**
- Microphone de qualitÃ© (Blue Yeti, Rode NT-USB, etc.)
- Environnement calme
- Pop filter (recommandÃ©)
- Logiciel d'enregistrement (Audacity, OBS, etc.)

**Protocole:**
1. **Participants**: 20-30 personnes
   - VariÃ©tÃ© d'Ã¢ges (20-60 ans)
   - Ã‰quilibre hommes/femmes
   - DiffÃ©rents accents si possible

2. **Sessions d'enregistrement**:
   - 5-10 rÃ©pÃ©titions par formule
   - Varier l'intonation (neutre, excitÃ©, sÃ©rieux)
   - Varier le volume (normal, chuchotÃ©, criÃ©)
   - Prendre des pauses entre les formules

3. **Configuration technique**:
   - Sample rate: 44100 Hz (on downsample Ã  16000 Hz aprÃ¨s)
   - Format: WAV, mono
   - Bit depth: 16-bit minimum
   - Distance du micro: 15-30 cm

4. **Instructions aux participants**:
   ```
   "Prononcez la formule [spell] comme si vous Ã©tiez un sorcier
   qui lance le sort. Vous pouvez Ãªtre neutre, excitÃ©, ou sÃ©rieux.
   RÃ©pÃ©tez 5 fois avec des intonations diffÃ©rentes."
   ```

#### Script d'enregistrement

```python
import sounddevice as sd
import soundfile as sf
import numpy as np

SAMPLE_RATE = 44100
DURATION = 3  # secondes

def record_spell(spell_name, speaker_id, repetition):
    print(f"Enregistrement de '{spell_name}' dans 3... 2... 1...")
    recording = sd.rec(
        int(DURATION * SAMPLE_RATE),
        samplerate=SAMPLE_RATE,
        channels=1
    )
    sd.wait()
    
    filename = f"data/raw/{spell_name}/speaker{speaker_id}_rep{repetition}.wav"
    sf.write(filename, recording, SAMPLE_RATE)
    print(f"âœ… SauvegardÃ©: {filename}")

# Usage
for spell in spells:
    for speaker in range(1, 21):  # 20 speakers
        for rep in range(1, 6):  # 5 rÃ©pÃ©titions
            record_spell(spell, speaker, rep)
```

### 3. Extraction de mÃ©dias existants

#### Sources potentielles
- Films Harry Potter (8 films)
- Jeux vidÃ©o Harry Potter
- Audiobooks
- Fan-made content (avec permission)

#### ConsidÃ©rations lÃ©gales
âš ï¸ **Important**: Respecter les droits d'auteur
- **Fair use Ã©ducatif**: Acceptable pour l'Ã©ducation et la recherche
- **Usage commercial**: NÃ©cessite autorisation
- **Attribution**: Toujours citer les sources

#### Extraction audio

```python
import moviepy.editor as mp

def extract_spell_from_video(video_path, start_time, end_time, spell_name):
    """
    Extrait un clip audio d'une vidÃ©o.
    """
    video = mp.VideoFileClip(video_path)
    audio = video.audio.subclip(start_time, end_time)
    audio.write_audiofile(f"data/raw/{spell_name}/movie_clip.wav")
    video.close()

# Exemple: extraire "Expelliarmus" du premier film
extract_spell_from_video(
    "harry_potter_1.mp4",
    start_time=(1, 23, 45),  # 1h 23m 45s
    end_time=(1, 23, 48),
    spell_name="expelliarmus"
)
```

## ğŸ”„ Data Augmentation

### Techniques appliquÃ©es

#### 1. Ajout de bruit
```python
def add_noise(audio, noise_factor=0.005):
    """Ajoute du bruit gaussien."""
    noise = np.random.normal(0, noise_factor, len(audio))
    return audio + noise
```

**Types de bruit Ã  ajouter:**
- Bruit blanc (gÃ©nÃ©ral)
- Bruit ambiant (cafÃ©, rue)
- Bruit Ã©lectronique (micro)

#### 2. Pitch shifting
```python
import librosa

def pitch_shift(audio, sr, n_steps):
    """Change le pitch de Â±n semi-tons."""
    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)

# Variations: -2, -1, +1, +2 semi-tons
```

**Simule:**
- DiffÃ©rentes voix (graves/aiguÃ«s)
- DiffÃ©rents Ã¢ges
- Effets magiques

#### 3. Time stretching
```python
def time_stretch(audio, rate):
    """AccÃ©lÃ¨re ou ralentit l'audio."""
    return librosa.effects.time_stretch(audio, rate=rate)

# Variations: 0.9x, 0.95x, 1.05x, 1.1x
```

**Simule:**
- Vitesse de parole diffÃ©rente
- Urgence/calme

#### 4. RÃ©verbÃ©ration
```python
import pyroomacoustics as pra

def add_reverb(audio, sr, room_dim=[10, 8, 3]):
    """Ajoute de la rÃ©verbÃ©ration."""
    room = pra.ShoeBox(room_dim, fs=sr, max_order=3)
    room.add_source([2, 2, 1.5], signal=audio)
    room.add_microphone([5, 5, 1.5])
    room.simulate()
    return room.mic_array.signals[0, :]
```

**Simule:**
- DiffÃ©rents environnements (salle, extÃ©rieur)
- ScÃ¨nes de combat magique

#### 5. Changement de volume
```python
def change_volume(audio, factor):
    """Augmente ou diminue le volume."""
    return audio * factor

# Variations: 0.7x, 0.85x, 1.15x, 1.3x
```

### Pipeline d'augmentation complet

```python
def augment_dataset(audio, sr):
    """
    Applique toutes les augmentations Ã  un Ã©chantillon.
    Retourne une liste d'Ã©chantillons augmentÃ©s.
    """
    augmented = [audio]  # Original
    
    # Ajout de bruit
    for noise_factor in [0.003, 0.005, 0.01]:
        augmented.append(add_noise(audio, noise_factor))
    
    # Pitch shifting
    for n_steps in [-2, -1, 1, 2]:
        augmented.append(pitch_shift(audio, sr, n_steps))
    
    # Time stretching
    for rate in [0.9, 0.95, 1.05, 1.1]:
        stretched = time_stretch(audio, rate)
        # Ajuste la longueur
        if len(stretched) > len(audio):
            stretched = stretched[:len(audio)]
        else:
            stretched = np.pad(stretched, (0, len(audio) - len(stretched)))
        augmented.append(stretched)
    
    # Changement de volume
    for factor in [0.7, 0.85, 1.15]:
        augmented.append(change_volume(audio, factor))
    
    # Combinaisons (ex: bruit + pitch)
    noise_pitch = pitch_shift(add_noise(audio, 0.005), sr, 1)
    augmented.append(noise_pitch)
    
    return augmented
```

## ğŸ“ PrÃ©traitement

### 1. Normalisation

```python
def normalize_audio(audio):
    """Normalise l'audio entre -1 et 1."""
    return audio / np.max(np.abs(audio))
```

### 2. Resampling

```python
import librosa

def resample_audio(audio, orig_sr, target_sr=16000):
    """Resample Ã  16kHz (standard pour la parole)."""
    return librosa.resample(audio, orig_sr=orig_sr, target_sr=target_sr)
```

### 3. Padding/Truncation

```python
def fix_length(audio, target_length):
    """Fixe la longueur de l'audio."""
    if len(audio) > target_length:
        return audio[:target_length]
    else:
        return np.pad(audio, (0, target_length - len(audio)))
```

### 4. Filtrage

```python
def remove_silence(audio, sr, threshold=0.01):
    """Retire les silences au dÃ©but et Ã  la fin."""
    # DÃ©tecte les parties non-silencieuses
    non_silent = librosa.effects.split(audio, top_db=20)
    
    # Garde seulement la partie parlÃ©e
    if len(non_silent) > 0:
        start, end = non_silent[0][0], non_silent[-1][1]
        return audio[start:end]
    return audio
```

## ğŸ“Š Structure finale du dataset

```
data/
â”œâ”€â”€ raw/                           # DonnÃ©es brutes
â”‚   â”œâ”€â”€ expelliarmus/
â”‚   â”‚   â”œâ”€â”€ tts_google_en.wav
â”‚   â”‚   â”œâ”€â”€ tts_polly_matthew.wav
â”‚   â”‚   â”œâ”€â”€ speaker001_rep1.wav
â”‚   â”‚   â”œâ”€â”€ speaker001_rep2.wav
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ lumos/
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ processed/                     # DonnÃ©es prÃ©traitÃ©es
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ expelliarmus/
â”‚   â”‚   â”‚   â”œâ”€â”€ 0001.wav
â”‚   â”‚   â”‚   â”œâ”€â”€ 0002.wav
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ test/
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ metadata/
    â”œâ”€â”€ train_metadata.csv        # Label, speaker, duration, etc.
    â””â”€â”€ test_metadata.csv
```

### Metadata format (CSV)

```csv
filename,spell,label,speaker_id,duration,augmentation,split
0001.wav,expelliarmus,0,speaker001,2.3,original,train
0002.wav,expelliarmus,0,speaker001,2.3,noise_0.005,train
0003.wav,expelliarmus,0,speaker001,2.3,pitch_+2,train
...
```

## ğŸ“ˆ Statistiques recommandÃ©es

### Dataset idÃ©al

| MÃ©trique | Valeur cible | Minimum acceptable |
|----------|--------------|-------------------|
| Ã‰chantillons par formule | 100-200 | 50 |
| Speakers uniques | 20-30 | 10 |
| RÃ©pÃ©titions par speaker | 5-10 | 3 |
| DurÃ©e moyenne | 2-3s | 1-4s |
| Total d'Ã©chantillons (bruts) | 1000-2000 | 500 |
| Total (avec augmentation) | 5000-10000 | 2000 |

### Distribution train/test

- **Train**: 80% (avec augmentation complÃ¨te)
- **Validation**: 10% (augmentation limitÃ©e)
- **Test**: 10% (pas d'augmentation)

**Important**: Les speakers du test set ne doivent PAS Ãªtre dans le train set (split par speaker, pas par Ã©chantillon).

## âœ… Checklist de qualitÃ©

### Avant l'entraÃ®nement

- [ ] Tous les fichiers sont au mÃªme sample rate (16kHz)
- [ ] Tous les fichiers sont mono
- [ ] DurÃ©es cohÃ©rentes (1-4 secondes)
- [ ] Pas de silences au dÃ©but/fin
- [ ] Volume normalisÃ©
- [ ] Distribution Ã©quilibrÃ©e des classes
- [ ] Metadata complÃ¨te et correcte
- [ ] Train/test split sans fuite de donnÃ©es

### Validation du dataset

```python
def validate_dataset(data_dir):
    """Valide la qualitÃ© du dataset."""
    issues = []
    
    for spell_dir in os.listdir(data_dir):
        spell_path = os.path.join(data_dir, spell_dir)
        files = os.listdir(spell_path)
        
        for file in files:
            filepath = os.path.join(spell_path, file)
            audio, sr = librosa.load(filepath)
            
            # VÃ©rifie le sample rate
            if sr != 16000:
                issues.append(f"{file}: Wrong sample rate ({sr})")
            
            # VÃ©rifie la durÃ©e
            duration = len(audio) / sr
            if duration < 0.5 or duration > 5:
                issues.append(f"{file}: Duration issue ({duration:.2f}s)")
            
            # VÃ©rifie le volume
            max_amp = np.max(np.abs(audio))
            if max_amp < 0.1:
                issues.append(f"{file}: Too quiet ({max_amp:.3f})")
            elif max_amp > 1.0:
                issues.append(f"{file}: Clipping ({max_amp:.3f})")
    
    return issues
```

## ğŸš€ Pipeline automatisÃ©

```python
def create_complete_dataset(spells, config):
    """
    Pipeline complet de crÃ©ation de dataset.
    """
    print("ğŸ“Š CrÃ©ation du dataset...")
    
    # 1. GÃ©nÃ©ration TTS
    print("1ï¸âƒ£ GÃ©nÃ©ration TTS...")
    generate_tts_samples(spells, config['tts_services'])
    
    # 2. PrÃ©traitement
    print("2ï¸âƒ£ PrÃ©traitement...")
    preprocess_all_files(config['raw_dir'], config['sample_rate'])
    
    # 3. Augmentation
    print("3ï¸âƒ£ Data augmentation...")
    augment_all_samples(config['raw_dir'], config['augmentation_params'])
    
    # 4. Split train/test
    print("4ï¸âƒ£ Split train/test...")
    split_dataset(config['raw_dir'], config['processed_dir'], test_size=0.2)
    
    # 5. Validation
    print("5ï¸âƒ£ Validation...")
    issues = validate_dataset(config['processed_dir'])
    if issues:
        print(f"âš ï¸ {len(issues)} issues trouvÃ©s")
        for issue in issues[:10]:
            print(f"  - {issue}")
    else:
        print("âœ… Dataset validÃ©!")
    
    # 6. GÃ©nÃ©ration des mÃ©tadonnÃ©es
    print("6ï¸âƒ£ GÃ©nÃ©ration des mÃ©tadonnÃ©es...")
    generate_metadata(config['processed_dir'])
    
    print("ğŸ‰ Dataset crÃ©Ã© avec succÃ¨s!")
```

## ğŸ“š Ressources et outils

### BibliothÃ¨ques Python
- `librosa` - Traitement audio
- `soundfile` - I/O audio
- `sounddevice` - Enregistrement
- `pydub` - Manipulation audio simple
- `pyroomacoustics` - Acoustique et rÃ©verbÃ©ration

### Services TTS
- Google Text-to-Speech (gratuit, limitÃ©)
- Amazon Polly (payant, haute qualitÃ©)
- Microsoft Azure TTS (payant)
- ElevenLabs (payant, trÃ¨s haute qualitÃ©)

### Outils d'enregistrement
- Audacity (gratuit, open source)
- Adobe Audition (professionnel, payant)
- OBS Studio (gratuit, streaming)

## ğŸ’¡ Conseils pratiques

1. **Commencez petit**: CrÃ©ez d'abord un dataset de 50 Ã©chantillons pour tester le pipeline
2. **ItÃ©rez**: EntraÃ®nez un premier modÃ¨le, identifiez les faiblesses, complÃ©tez le dataset
3. **Documentez**: Gardez trace de chaque source de donnÃ©es
4. **Versionnez**: Utilisez Git LFS pour versionner les donnÃ©es
5. **Partagez**: ConsidÃ©rez publier le dataset (avec permissions appropriÃ©es)

---

âœ¨ *"La qualitÃ© du dataset dÃ©termine la qualitÃ© du modÃ¨le"*
