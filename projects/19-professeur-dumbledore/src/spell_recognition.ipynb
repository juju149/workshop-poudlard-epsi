{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßô‚Äç‚ôÇÔ∏è Professeur Dumbledore - Reconnaissance Vocale de Formules Magiques\n",
    "\n",
    "Ce notebook impl√©mente un syst√®me de reconnaissance vocale capable d'identifier au moins 8 formules magiques de l'univers Harry Potter.\n",
    "\n",
    "## üìã Formules magiques reconnues\n",
    "\n",
    "1. **Expelliarmus** - Sortil√®ge de d√©sarmement\n",
    "2. **Lumos** - Sortil√®ge de lumi√®re\n",
    "3. **Nox** - √âteint la lumi√®re\n",
    "4. **Wingardium Leviosa** - Sortil√®ge de l√©vitation\n",
    "5. **Alohomora** - Sortil√®ge d'ouverture\n",
    "6. **Expecto Patronum** - Invoque un patronus\n",
    "7. **Avada Kedavra** - Sort impardonnable\n",
    "8. **Stupefix** - Sortil√®ge de stup√©fixion\n",
    "9. **Protego** - Bouclier protecteur\n",
    "10. **Accio** - Sortil√®ge d'attraction\n",
    "\n",
    "## üîß Architecture du mod√®le\n",
    "\n",
    "Nous utilisons une approche hybride:\n",
    "- **Wav2Vec2** pour l'extraction de features audio\n",
    "- **Classification fine-tuning** pour identifier les formules\n",
    "- **Data augmentation** pour enrichir le dataset limit√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des d√©pendances\n",
    "!pip install -q transformers datasets librosa soundfile torch torchaudio numpy pandas scikit-learn matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "SAMPLE_RATE = 16000\n",
    "MAX_DURATION = 3  # secondes\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 1. Cr√©ation du Dataset\n",
    "\n",
    "### M√©thodologie de cr√©ation du dataset\n",
    "\n",
    "Pour cr√©er un dataset de reconnaissance vocale de formules magiques, nous utilisons plusieurs approches:\n",
    "\n",
    "1. **Synth√®se vocale (TTS)** : Utilisation de services de synth√®se vocale pour g√©n√©rer des √©chantillons\n",
    "2. **Enregistrements multiples** : Plusieurs voix et intonations diff√©rentes\n",
    "3. **Data augmentation** : Ajout de bruit, changement de pitch, time stretching\n",
    "4. **Variations phon√©tiques** : Diff√©rentes prononciations et accents\n",
    "\n",
    "Pour ce notebook de d√©monstration, nous g√©n√©rons des √©chantillons synth√©tiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition des formules magiques\n",
    "SPELLS = [\n",
    "    \"expelliarmus\",\n",
    "    \"lumos\",\n",
    "    \"nox\",\n",
    "    \"wingardium leviosa\",\n",
    "    \"alohomora\",\n",
    "    \"expecto patronum\",\n",
    "    \"avada kedavra\",\n",
    "    \"stupefix\",\n",
    "    \"protego\",\n",
    "    \"accio\"\n",
    "]\n",
    "\n",
    "spell_to_id = {spell: idx for idx, spell in enumerate(SPELLS)}\n",
    "id_to_spell = {idx: spell for idx, spell in enumerate(SPELLS)}\n",
    "\n",
    "print(f\"Nombre de formules: {len(SPELLS)}\")\n",
    "print(f\"Classes: {SPELLS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour g√©n√©rer des √©chantillons audio synth√©tiques\n",
    "# Note: Dans un cas r√©el, vous utiliseriez des enregistrements r√©els ou TTS\n",
    "def generate_synthetic_audio(spell, duration=2.0, sr=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    G√©n√®re un signal audio synth√©tique pour une formule.\n",
    "    IMPORTANT: Ceci est une simulation. Dans un projet r√©el:\n",
    "    - Utilisez gTTS, Amazon Polly, ou Google TTS pour g√©n√©rer de vrais √©chantillons\n",
    "    - Enregistrez de vraies voix pronon√ßant les formules\n",
    "    - Collectez des √©chantillons de films/s√©ries Harry Potter\n",
    "    \"\"\"\n",
    "    # Cr√©e un signal bas√© sur le hash du nom du sort pour la coh√©rence\n",
    "    np.random.seed(hash(spell) % (2**32))\n",
    "    \n",
    "    # G√©n√®re un signal avec plusieurs composantes fr√©quentielles\n",
    "    t = np.linspace(0, duration, int(sr * duration))\n",
    "    \n",
    "    # Fr√©quences bas√©es sur les caract√©ristiques de la parole (100-8000 Hz)\n",
    "    fundamental = 100 + (hash(spell) % 200)  # Fr√©quence fondamentale\n",
    "    \n",
    "    # Cr√©e un signal composite\n",
    "    signal = np.zeros_like(t)\n",
    "    for harmonic in range(1, 6):\n",
    "        freq = fundamental * harmonic\n",
    "        amplitude = 0.3 / harmonic\n",
    "        signal += amplitude * np.sin(2 * np.pi * freq * t)\n",
    "    \n",
    "    # Ajoute une enveloppe (attaque, sustain, release)\n",
    "    envelope = np.ones_like(t)\n",
    "    attack = int(0.1 * len(t))\n",
    "    release = int(0.2 * len(t))\n",
    "    envelope[:attack] = np.linspace(0, 1, attack)\n",
    "    envelope[-release:] = np.linspace(1, 0, release)\n",
    "    signal *= envelope\n",
    "    \n",
    "    # Ajoute un peu de bruit pour plus de r√©alisme\n",
    "    noise = np.random.normal(0, 0.02, len(signal))\n",
    "    signal += noise\n",
    "    \n",
    "    # Normalise\n",
    "    signal = signal / np.max(np.abs(signal)) * 0.8\n",
    "    \n",
    "    return signal.astype(np.float32)\n",
    "\n",
    "# Test de g√©n√©ration\n",
    "test_audio = generate_synthetic_audio(\"expelliarmus\")\n",
    "print(f\"Audio g√©n√©r√©: shape={test_audio.shape}, dtype={test_audio.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'augmentation de donn√©es\n",
    "def augment_audio(audio, sr=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Applique des techniques d'augmentation de donn√©es sur l'audio.\n",
    "    \"\"\"\n",
    "    augmented = []\n",
    "    \n",
    "    # Original\n",
    "    augmented.append(audio)\n",
    "    \n",
    "    # Ajout de bruit\n",
    "    noise = np.random.normal(0, 0.005, len(audio))\n",
    "    augmented.append(audio + noise)\n",
    "    \n",
    "    # Changement de pitch (¬±2 semi-tons)\n",
    "    for n_steps in [-2, 2]:\n",
    "        pitched = librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
    "        augmented.append(pitched)\n",
    "    \n",
    "    # Time stretching\n",
    "    for rate in [0.9, 1.1]:\n",
    "        stretched = librosa.effects.time_stretch(audio, rate=rate)\n",
    "        # Ajuste la longueur\n",
    "        if len(stretched) > len(audio):\n",
    "            stretched = stretched[:len(audio)]\n",
    "        else:\n",
    "            stretched = np.pad(stretched, (0, len(audio) - len(stretched)))\n",
    "        augmented.append(stretched)\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "print(\"Fonctions d'augmentation pr√™tes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G√©n√©ration du dataset complet\n",
    "def create_dataset(spells, samples_per_spell=10, augment=True):\n",
    "    \"\"\"\n",
    "    Cr√©e un dataset complet avec augmentation.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    print(\"G√©n√©ration du dataset...\")\n",
    "    for spell in tqdm(spells):\n",
    "        spell_id = spell_to_id[spell]\n",
    "        \n",
    "        for i in range(samples_per_spell):\n",
    "            # G√©n√®re l'audio de base avec variation\n",
    "            duration = np.random.uniform(1.5, 2.5)\n",
    "            audio = generate_synthetic_audio(spell + str(i), duration=duration)\n",
    "            \n",
    "            if augment:\n",
    "                # Applique l'augmentation\n",
    "                augmented_audios = augment_audio(audio)\n",
    "                for aug_audio in augmented_audios:\n",
    "                    data.append({\n",
    "                        'audio': aug_audio,\n",
    "                        'label': spell_id,\n",
    "                        'spell': spell\n",
    "                    })\n",
    "            else:\n",
    "                data.append({\n",
    "                    'audio': audio,\n",
    "                    'label': spell_id,\n",
    "                    'spell': spell\n",
    "                })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Cr√©e le dataset\n",
    "dataset_raw = create_dataset(SPELLS, samples_per_spell=5, augment=True)\n",
    "print(f\"\\nDataset cr√©√©: {len(dataset_raw)} √©chantillons\")\n",
    "\n",
    "# Affiche la distribution\n",
    "labels = [item['label'] for item in dataset_raw]\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(\"\\nDistribution des classes:\")\n",
    "for spell_id, count in zip(unique, counts):\n",
    "    print(f\"  {id_to_spell[spell_id]}: {count} √©chantillons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ 2. Pr√©traitement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©traitement: padding/truncation √† une longueur fixe\n",
    "def preprocess_audio(audio, target_length=SAMPLE_RATE * MAX_DURATION):\n",
    "    \"\"\"\n",
    "    Pr√©traite l'audio pour avoir une longueur fixe.\n",
    "    \"\"\"\n",
    "    if len(audio) > target_length:\n",
    "        # Tronque\n",
    "        audio = audio[:target_length]\n",
    "    elif len(audio) < target_length:\n",
    "        # Padding\n",
    "        audio = np.pad(audio, (0, target_length - len(audio)), mode='constant')\n",
    "    \n",
    "    return audio\n",
    "\n",
    "# Applique le pr√©traitement\n",
    "for item in dataset_raw:\n",
    "    item['audio'] = preprocess_audio(item['audio'])\n",
    "\n",
    "print(\"Pr√©traitement termin√©\")\n",
    "print(f\"Longueur audio: {len(dataset_raw[0]['audio'])} samples ({len(dataset_raw[0]['audio'])/SAMPLE_RATE:.2f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "train_data, test_data = train_test_split(dataset_raw, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "print(f\"Train set: {len(train_data)} √©chantillons\")\n",
    "print(f\"Test set: {len(test_data)} √©chantillons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ 3. Mod√®le de reconnaissance\n",
    "\n",
    "Nous utilisons Wav2Vec2, un mod√®le pr√©-entra√Æn√© sur de la parole, que nous fine-tunons pour notre t√¢che de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge le feature extractor et le mod√®le\n",
    "model_name = \"facebook/wav2vec2-base\"\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "# Mod√®le de classification\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(SPELLS),\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "model.to(DEVICE)\n",
    "\n",
    "print(f\"Mod√®le charg√©: {model_name}\")\n",
    "print(f\"Nombre de param√®tres: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©paration des donn√©es pour le mod√®le\n",
    "def prepare_dataset(data):\n",
    "    \"\"\"\n",
    "    Pr√©pare les donn√©es pour l'entra√Ænement.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "    \n",
    "    for item in data:\n",
    "        # Extrait les features\n",
    "        inputs = feature_extractor(\n",
    "            item['audio'],\n",
    "            sampling_rate=SAMPLE_RATE,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True\n",
    "        )\n",
    "        \n",
    "        processed_data.append({\n",
    "            'input_values': inputs.input_values.squeeze(),\n",
    "            'labels': item['label']\n",
    "        })\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "print(\"Pr√©paration des datasets pour l'entra√Ænement...\")\n",
    "train_dataset = prepare_dataset(train_data)\n",
    "test_dataset = prepare_dataset(test_data)\n",
    "print(\"Datasets pr√™ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertit en Dataset HuggingFace\n",
    "train_hf = Dataset.from_list(train_dataset)\n",
    "test_hf = Dataset.from_list(test_dataset)\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_hf,\n",
    "    'test': test_hf\n",
    "})\n",
    "\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì 4. Entra√Ænement du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de calcul des m√©triques\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    labels = eval_pred.label_ids\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de l'entra√Ænement\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/spell-recognition\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    logging_dir=\"../models/logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_hf,\n",
    "    eval_dataset=test_hf,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Trainer configur√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænement\n",
    "print(\"D√©but de l'entra√Ænement...\")\n",
    "train_result = trainer.train()\n",
    "print(\"\\nEntra√Ænement termin√©!\")\n",
    "print(train_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 5. √âvaluation des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âvaluation sur le test set\n",
    "print(\"√âvaluation sur le test set...\")\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"\\nüìä R√©sultats de l'√©valuation:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions pour la matrice de confusion\n",
    "predictions = trainer.predict(test_hf)\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=SPELLS, yticklabels=SPELLS)\n",
    "plt.title('Matrice de Confusion - Reconnaissance de Formules Magiques')\n",
    "plt.ylabel('Vraie Formule')\n",
    "plt.xlabel('Formule Pr√©dite')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Matrice de confusion sauvegard√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√©triques par classe\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=SPELLS, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nüìä Rapport de classification par formule:\")\n",
    "print(report_df.to_string())\n",
    "\n",
    "# Sauvegarde le rapport\n",
    "report_df.to_csv('../models/classification_report.csv')\n",
    "print(\"\\nRapport sauvegard√© dans models/classification_report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des m√©triques par formule\n",
    "spell_metrics = report_df.iloc[:-3]  # Exclut les moyennes\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Precision\n",
    "axes[0].bar(range(len(spell_metrics)), spell_metrics['precision'])\n",
    "axes[0].set_title('Precision par Formule')\n",
    "axes[0].set_xticks(range(len(SPELLS)))\n",
    "axes[0].set_xticklabels(SPELLS, rotation=45, ha='right')\n",
    "axes[0].set_ylim([0, 1])\n",
    "\n",
    "# Recall\n",
    "axes[1].bar(range(len(spell_metrics)), spell_metrics['recall'])\n",
    "axes[1].set_title('Recall par Formule')\n",
    "axes[1].set_xticks(range(len(SPELLS)))\n",
    "axes[1].set_xticklabels(SPELLS, rotation=45, ha='right')\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "# F1-Score\n",
    "axes[2].bar(range(len(spell_metrics)), spell_metrics['f1-score'])\n",
    "axes[2].set_title('F1-Score par Formule')\n",
    "axes[2].set_xticks(range(len(SPELLS)))\n",
    "axes[2].set_xticklabels(SPELLS, rotation=45, ha='right')\n",
    "axes[2].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/metrics_by_spell.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Graphiques des m√©triques sauvegard√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ 6. Sauvegarde du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde le mod√®le et le feature extractor\n",
    "model.save_pretrained('../models/spell-recognition-final')\n",
    "feature_extractor.save_pretrained('../models/spell-recognition-final')\n",
    "\n",
    "# Sauvegarde la configuration\n",
    "import json\n",
    "\n",
    "config = {\n",
    "    'spells': SPELLS,\n",
    "    'spell_to_id': spell_to_id,\n",
    "    'id_to_spell': id_to_spell,\n",
    "    'sample_rate': SAMPLE_RATE,\n",
    "    'max_duration': MAX_DURATION,\n",
    "    'model_name': model_name,\n",
    "    'metrics': {\n",
    "        'accuracy': float(eval_results['eval_accuracy']),\n",
    "        'precision': float(eval_results['eval_precision']),\n",
    "        'recall': float(eval_results['eval_recall']),\n",
    "        'f1': float(eval_results['eval_f1'])\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('../models/spell-recognition-final/config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Mod√®le sauvegard√© dans models/spell-recognition-final/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ 7. Test d'inf√©rence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'inf√©rence\n",
    "def predict_spell(audio, model, feature_extractor):\n",
    "    \"\"\"\n",
    "    Pr√©dit la formule magique √† partir d'un √©chantillon audio.\n",
    "    \"\"\"\n",
    "    # Pr√©traite l'audio\n",
    "    audio = preprocess_audio(audio)\n",
    "    \n",
    "    # Extrait les features\n",
    "    inputs = feature_extractor(\n",
    "        audio,\n",
    "        sampling_rate=SAMPLE_RATE,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    # Pr√©diction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        predicted_id = torch.argmax(probabilities, dim=-1).item()\n",
    "    \n",
    "    predicted_spell = id_to_spell[predicted_id]\n",
    "    confidence = probabilities[0][predicted_id].item()\n",
    "    \n",
    "    return predicted_spell, confidence, probabilities[0].cpu().numpy()\n",
    "\n",
    "# Test sur quelques √©chantillons\n",
    "print(\"\\nüß™ Tests d'inf√©rence:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i in range(min(5, len(test_data))):\n",
    "    test_sample = test_data[i]\n",
    "    true_spell = test_sample['spell']\n",
    "    \n",
    "    predicted_spell, confidence, probs = predict_spell(\n",
    "        test_sample['audio'], model, feature_extractor\n",
    "    )\n",
    "    \n",
    "    status = \"‚úÖ\" if predicted_spell == true_spell else \"‚ùå\"\n",
    "    print(f\"{status} Vraie formule: {true_spell:20s} | Pr√©dite: {predicted_spell:20s} | Confiance: {confidence:.2%}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù R√©sum√© des r√©sultats\n",
    "\n",
    "### M√©triques globales\n",
    "- **Accuracy**: Performance globale du mod√®le\n",
    "- **Precision**: Proportion de pr√©dictions correctes parmi les positives\n",
    "- **Recall**: Proportion de vrais positifs identifi√©s\n",
    "- **F1-Score**: Moyenne harmonique de precision et recall\n",
    "\n",
    "### Points cl√©s\n",
    "1. ‚úÖ Le mod√®le reconna√Æt 10 formules magiques (> 8 requis)\n",
    "2. ‚úÖ Utilisation de Wav2Vec2 pr√©-entra√Æn√© + fine-tuning\n",
    "3. ‚úÖ Data augmentation pour enrichir le dataset\n",
    "4. ‚úÖ M√©triques compl√®tes et visualisations\n",
    "\n",
    "### Am√©liorations possibles\n",
    "- Utiliser des enregistrements r√©els de voix humaines\n",
    "- Augmenter la taille du dataset (100+ √©chantillons par formule)\n",
    "- Tester d'autres architectures (HuBERT, Whisper)\n",
    "- Ajouter des variations de prononciation (accents)\n",
    "- Impl√©menter la d√©tection en temps r√©el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche un r√©sum√© final\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ ENTRA√éNEMENT TERMIN√â\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä M√©triques finales:\")\n",
    "print(f\"  ‚Ä¢ Accuracy:  {eval_results['eval_accuracy']:.2%}\")\n",
    "print(f\"  ‚Ä¢ Precision: {eval_results['eval_precision']:.2%}\")\n",
    "print(f\"  ‚Ä¢ Recall:    {eval_results['eval_recall']:.2%}\")\n",
    "print(f\"  ‚Ä¢ F1-Score:  {eval_results['eval_f1']:.2%}\")\n",
    "print(f\"\\nüì¶ Livrables:\")\n",
    "print(f\"  ‚Ä¢ Mod√®le entra√Æn√©: models/spell-recognition-final/\")\n",
    "print(f\"  ‚Ä¢ Rapport de classification: models/classification_report.csv\")\n",
    "print(f\"  ‚Ä¢ Matrice de confusion: docs/confusion_matrix.png\")\n",
    "print(f\"  ‚Ä¢ M√©triques par formule: docs/metrics_by_spell.png\")\n",
    "print(f\"\\n‚ú® Formules magiques reconnues: {len(SPELLS)}\")\n",
    "for spell in SPELLS:\n",
    "    print(f\"  ‚Ä¢ {spell}\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
