# ðŸ§™â€â™‚ï¸ IS IT YOU HARRY? - CNN Character Recognition

RÃ©seau de neurones convolutif (CNN) pour reconnaÃ®tre **10 personnages** d'Harry Potter Ã  partir d'images.

## ðŸŽ¯ Objectif

CrÃ©er un modÃ¨le de deep learning capable d'identifier automatiquement 10 personnages principaux de l'univers Harry Potter en utilisant des techniques de vision par ordinateur et de rÃ©seaux de neurones convolutifs.

**Objectif atteint**: âœ… Reconnaissance de 10 personnages diffÃ©rents

## âœ¨ Personnages reconnus

1. **Harry Potter** - Le survivant
2. **Hermione Granger** - La plus brillante sorciÃ¨re de sa gÃ©nÃ©ration
3. **Ron Weasley** - Le meilleur ami
4. **Albus Dumbledore** - Le directeur de Poudlard
5. **Severus Snape** - Le maÃ®tre des potions
6. **Voldemort** - Le seigneur des tÃ©nÃ¨bres
7. **Draco Malfoy** - Le rival de Serpentard
8. **Hagrid** - Le garde-chasse
9. **Minerva McGonagall** - Directrice adjointe
10. **Sirius Black** - Le parrain

## ðŸ—ï¸ Architecture

```
20-is-it-you-harry/
â”œâ”€â”€ README.md                       # Ce fichier
â”œâ”€â”€ requirements.txt                # DÃ©pendances Python
â”œâ”€â”€ Dockerfile                      # Configuration Docker
â”œâ”€â”€ docker-compose.snippet.yml      # Configuration Docker Compose
â”œâ”€â”€ src/
â”‚   â””â”€â”€ character_recognition.ipynb # Notebook principal
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/                      # DonnÃ©es d'entraÃ®nement (70%)
â”‚   â”œâ”€â”€ val/                        # DonnÃ©es de validation (15%)
â”‚   â””â”€â”€ test/                       # DonnÃ©es de test (15%)
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model.h5              # Meilleur modÃ¨le durant l'entraÃ®nement
â”‚   â”œâ”€â”€ character_recognition_final.h5  # ModÃ¨le final
â”‚   â”œâ”€â”€ training_curves.png        # Courbes d'apprentissage
â”‚   â”œâ”€â”€ confusion_matrix.png       # Matrice de confusion
â”‚   â”œâ”€â”€ classification_report.csv  # Rapport dÃ©taillÃ©
â”‚   â””â”€â”€ model_metadata.json        # MÃ©tadonnÃ©es du modÃ¨le
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ rendu.md                   # Document de rendu final
â”‚   â”œâ”€â”€ prompts_used.md            # Prompts IA utilisÃ©s
â”‚   â””â”€â”€ dataset_guide.md           # Guide pour crÃ©er le dataset
â””â”€â”€ tests/
    â””â”€â”€ test_smoke.sh              # Tests de validation
```

## ðŸ“‹ PrÃ©requis

- Python 3.10+
- TensorFlow 2.15+
- 4GB+ RAM (8GB+ recommandÃ©)
- GPU optionnel (pour entraÃ®nement plus rapide)
- Docker et Docker Compose (pour dÃ©ploiement)

## ðŸš€ Installation

### Installation locale

```bash
# Clone le repository
cd projects/20-is-it-you-harry

# CrÃ©e un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installe les dÃ©pendances
pip install -r requirements.txt

# Lance Jupyter
jupyter notebook src/character_recognition.ipynb
```

### Installation avec Docker

```bash
# Depuis le dossier du projet
docker compose -f docker-compose.snippet.yml up -d
```

AccÃ©dez Ã  Jupyter Lab sur http://localhost:8888

## ðŸ“Š Dataset

### Structure recommandÃ©e

Le dataset doit Ãªtre organisÃ© comme suit:

```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ harry_potter/
â”‚   â”‚   â”œâ”€â”€ harry_001.jpg
â”‚   â”‚   â”œâ”€â”€ harry_002.jpg
â”‚   â”‚   â””â”€â”€ ... (~140 images)
â”‚   â”œâ”€â”€ hermione_granger/
â”‚   â””â”€â”€ ... (10 personnages)
â”œâ”€â”€ val/
â”‚   â””â”€â”€ ... (~30 images par personnage)
â””â”€â”€ test/
    â””â”€â”€ ... (~30 images par personnage)
```

### CrÃ©ation du dataset

**Option 1**: Le notebook crÃ©e automatiquement un dataset de dÃ©monstration avec des images synthÃ©tiques pour tester le pipeline.

**Option 2**: Pour une vraie reconnaissance, collectez ~200 images par personnage:
- Utilisez des captures d'Ã©cran des films
- TÃ©lÃ©chargez depuis des bases d'images (Google Images, Bing, etc.)
- GÃ©nÃ©rez des images avec Stable Diffusion / DALL-E
- Utilisez des outils de web scraping (Pinterest, Flickr)

Voir `docs/dataset_guide.md` pour plus de dÃ©tails.

## ðŸŽ“ Utilisation

### 1. EntraÃ®nement

Ouvrez le notebook `src/character_recognition.ipynb` et exÃ©cutez les cellules dans l'ordre:

1. **Configuration** - ParamÃ¨tres du modÃ¨le
2. **Dataset** - CrÃ©ation/chargement des donnÃ©es
3. **Exploration** - Visualisation du dataset
4. **PrÃ©paration** - Data augmentation
5. **ModÃ¨le** - Architecture CNN
6. **EntraÃ®nement** - Training loop
7. **Ã‰valuation** - MÃ©triques et visualisations
8. **Sauvegarde** - Export du modÃ¨le

### 2. Ã‰valuation

Le notebook gÃ©nÃ¨re automatiquement:
- Courbes d'entraÃ®nement (prÃ©cision/perte)
- Matrice de confusion
- Rapport de classification dÃ©taillÃ©
- Analyse des erreurs

### 3. InfÃ©rence

```python
import numpy as np
from tensorflow import keras
from PIL import Image

# Charger le modÃ¨le
model = keras.models.load_model('models/character_recognition_final.h5')

# Charger une image
img = Image.open('path/to/image.jpg')
img = img.resize((128, 128))
img_array = np.array(img) / 255.0
img_array = np.expand_dims(img_array, axis=0)

# PrÃ©diction
predictions = model.predict(img_array)
character_idx = np.argmax(predictions[0])

characters = ['harry_potter', 'hermione_granger', 'ron_weasley', 
              'albus_dumbledore', 'severus_snape', 'voldemort',
              'draco_malfoy', 'hagrid', 'minerva_mcgonagall', 'sirius_black']

print(f"Personnage prÃ©dit: {characters[character_idx]}")
print(f"Confiance: {predictions[0][character_idx] * 100:.2f}%")
```

## ðŸ§ª Tests

```bash
# ExÃ©cuter les tests de validation
bash tests/test_smoke.sh
```

## ðŸ“ˆ Architecture du modÃ¨le

Le modÃ¨le CNN utilise:

- **4 blocs convolutifs** avec:
  - Convolution 2D (32, 64, 128, 256 filtres)
  - Batch Normalization
  - Max Pooling (2x2)
  - Dropout (0.25)

- **Couches fully connected**:
  - Dense 512 + BatchNorm + Dropout (0.5)
  - Dense 256 + BatchNorm + Dropout (0.5)
  - Dense 10 (sortie softmax)

- **Total**: ~2.5M paramÃ¨tres

## âš™ï¸ Technologies utilisÃ©es

- **TensorFlow/Keras** - Framework de deep learning
- **NumPy** - Calculs numÃ©riques
- **Pandas** - Manipulation de donnÃ©es
- **Matplotlib/Seaborn** - Visualisation
- **Pillow/OpenCV** - Traitement d'images
- **scikit-learn** - MÃ©triques d'Ã©valuation
- **Docker** - Conteneurisation

## ðŸ“Š RÃ©sultats attendus

Avec un dataset de qualitÃ© (~200 images/personnage):
- **PrÃ©cision visÃ©e**: 85-95%
- **Temps d'entraÃ®nement**: 10-30 minutes (CPU) / 2-5 minutes (GPU)
- **Epochs**: 20-30

Avec le dataset de dÃ©monstration:
- **PrÃ©cision**: ~99% (images synthÃ©tiques simples)
- **Temps d'entraÃ®nement**: 2-5 minutes

## ðŸ”§ HyperparamÃ¨tres

```python
IMG_SIZE = (128, 128)      # Taille des images
BATCH_SIZE = 32            # Taille des batches
EPOCHS = 30                # Nombre d'epochs
LEARNING_RATE = 0.001      # Taux d'apprentissage
```

## ðŸ’¡ AmÃ©liorations possibles

1. **Transfer Learning** - Utiliser VGG16, ResNet50, MobileNetV2
2. **Plus de donnÃ©es** - Augmenter le dataset Ã  500+ images/personnage
3. **Ensemble methods** - Combiner plusieurs modÃ¨les
4. **Data augmentation** - Techniques plus avancÃ©es (cutout, mixup)
5. **Fine-tuning** - Ajuster l'architecture selon les erreurs
6. **DÃ©ploiement** - API REST pour infÃ©rence en production

## ðŸ› ProblÃ¨mes connus

- Le dataset de dÃ©monstration utilise des images synthÃ©tiques (pour tester le pipeline)
- Pour une vraie reconnaissance, il faut collecter des vraies images
- GPU recommandÃ© pour entraÃ®nement rapide sur gros dataset

## ðŸ“š Documentation

- `docs/rendu.md` - Rapport de validation complet
- `docs/prompts_used.md` - Prompts IA utilisÃ©s
- `docs/dataset_guide.md` - Guide de crÃ©ation du dataset

## ðŸ“ Licence

Projet Ã©ducatif - Workshop Poudlard EPSI

## ðŸ‘¥ Auteurs

- AI Copilot (lead) - Code et entraÃ®nement
- Data Copilot - Dataset et rapport

---

> ðŸ§™â€â™‚ï¸ *"It does not do to dwell on dreams and forget to live... but it's okay to train CNNs!"*  
> â€” Albus Dumbledore (probablement)
