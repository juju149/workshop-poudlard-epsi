# ðŸ’¬ Prompts IA utilisÃ©s â€“ DÃ©fi 20: IS IT YOU HARRY?

Ce document liste tous les prompts utilisÃ©s avec des outils d'IA pour gÃ©nÃ©rer le code, la documentation et l'architecture de ce projet de reconnaissance de personnages Harry Potter par CNN.

---

## ðŸ”¹ Prompt 1 â€“ Architecture globale du projet

**Date**: 2025-10-15  
**Outil**: GitHub Copilot  
**Objectif**: DÃ©finir la structure complÃ¨te du projet

```
CrÃ©e la structure d'un projet de deep learning pour reconnaÃ®tre 10 personnages 
d'Harry Potter avec un CNN. Le projet doit suivre la convention du workshop 
Poudlard EPSI:

- Structure: projects/20-is-it-you-harry/
- Inclure: src/, data/, models/, docs/, tests/
- Fichiers: Dockerfile, docker-compose.snippet.yml, requirements.txt
- Documentation: README.md, docs/rendu.md, docs/prompts_used.md
- Dataset organisÃ© en train/val/test (70/15/15)
- Notebook Jupyter principal pour tout le pipeline
- Tests automatiques (test_smoke.sh)

Utiliser TensorFlow/Keras pour le modÃ¨le CNN.
```

---

## ðŸ”¹ Prompt 2 â€“ Notebook Jupyter principal

**Date**: 2025-10-15  
**Outil**: GitHub Copilot  
**Objectif**: CrÃ©er le notebook complet avec pipeline ML

```
CrÃ©e un notebook Jupyter (character_recognition.ipynb) pour reconnaÃ®tre 
10 personnages d'Harry Potter avec un CNN. Le notebook doit inclure:

1. Introduction et objectifs
2. Import des bibliothÃ¨ques (TensorFlow, Keras, NumPy, Pandas, Matplotlib, etc.)
3. Configuration (chemins, hyperparamÃ¨tres, liste des personnages)
4. Fonction pour crÃ©er un dataset de dÃ©monstration avec images synthÃ©tiques
5. Exploration du dataset (statistiques, visualisations)
6. Data augmentation avec ImageDataGenerator
7. Architecture CNN personnalisÃ©e:
   - 4 blocs convolutifs (32, 64, 128, 256 filtres)
   - BatchNormalization et Dropout
   - 2 couches fully connected (512, 256)
   - Sortie softmax (10 classes)
8. Callbacks: ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
9. EntraÃ®nement du modÃ¨le
10. Visualisation des courbes (accuracy, loss)
11. Ã‰valuation sur test set
12. Matrice de confusion avec Seaborn
13. Rapport de classification dÃ©taillÃ©
14. Sauvegarde du modÃ¨le et mÃ©tadonnÃ©es
15. Analyse des erreurs
16. RÃ©sumÃ© final avec statistiques

Personnages: Harry, Hermione, Ron, Dumbledore, Snape, Voldemort, Draco, 
Hagrid, McGonagall, Sirius Black

Utiliser des commentaires et markdown cells pour expliquer chaque Ã©tape.
```

---

## ðŸ”¹ Prompt 3 â€“ README.md

**Date**: 2025-10-15  
**Outil**: GitHub Copilot  
**Objectif**: CrÃ©er la documentation principale du projet

```
RÃ©dige un README.md complet pour le projet de reconnaissance de personnages 
Harry Potter par CNN. Inclure:

1. Titre avec emoji et description
2. Objectif du projet
3. Liste des 10 personnages reconnus
4. Architecture du projet (arborescence des fichiers)
5. PrÃ©requis (Python, TensorFlow, Docker)
6. Installation (locale et Docker)
7. Structure du dataset recommandÃ©e
8. Guide d'utilisation (entraÃ®nement, Ã©valuation, infÃ©rence)
9. Tests (commande pour test_smoke.sh)
10. Architecture du modÃ¨le CNN (dÃ©tails techniques)
11. Technologies utilisÃ©es
12. RÃ©sultats attendus (prÃ©cision, temps)
13. HyperparamÃ¨tres
14. AmÃ©liorations possibles
15. ProblÃ¨mes connus
16. Documentation associÃ©e
17. Licence et auteurs
18. Citation Harry Potter en conclusion

Style: Clair, professionnel, avec emojis pour rendre attractif.
Format: Markdown avec code blocks, tableaux, listes.
```

---

## ðŸ”¹ Prompt 4 â€“ Documentation rendu.md

**Date**: 2025-10-15  
**Outil**: GitHub Copilot  
**Objectif**: CrÃ©er le document de rendu pour le jury

```
RÃ©dige un document de rendu complet (docs/rendu.md) pour le dÃ©fi 20 
"IS IT YOU HARRY?" selon le template standard du workshop Poudlard.

Sections obligatoires:
1. ðŸŽ¯ Objectif - Description claire de l'objectif atteint
2. ðŸ§© Architecture - Composants, pipeline, architecture CNN dÃ©taillÃ©e en ASCII
3. âš™ï¸ Technologies utilisÃ©es - Liste complÃ¨te avec versions
4. ðŸš€ Lancement rapide - Commandes Docker et local
5. ðŸ“Š Dataset - Structure, personnages, crÃ©ation, data augmentation
6. ðŸŽ“ EntraÃ®nement - HyperparamÃ¨tres, callbacks, optimiseur, durÃ©e
7. ðŸ“ˆ RÃ©sultats - MÃ©triques, visualisations, fichiers gÃ©nÃ©rÃ©s
8. ðŸ§ª Tests - Script de validation
9. ðŸ” Analyse des erreurs - Erreurs typiques et pistes d'amÃ©lioration
10. ðŸ’¾ ModÃ¨le entraÃ®nÃ© - Chargement et infÃ©rence
11. ðŸ› Limitations - ProblÃ¨mes connus
12. ðŸ“š Documentation complÃ©mentaire
13. ðŸŽ¯ Checklist de validation
14. ðŸ† Conclusion - Points forts et prochaines Ã©tapes

Inclure des tableaux, des diagrammes ASCII, et des exemples de code.
Style: Professionnel mais accessible, avec emojis.
```

---

## ðŸ”¹ Prompt 5 â€“ Dataset guide

**Date**: 2025-10-15  
**Outil**: GitHub Copilot  
**Objectif**: Guide pour crÃ©er le dataset rÃ©el

```
CrÃ©e un guide pratique (docs/dataset_guide.md) pour collecter et organiser 
un dataset d'images de personnages Harry Potter. Inclure:

1. Introduction - Pourquoi un bon dataset est crucial
2. MÃ©thodes de collecte:
   - Web scraping (Google Images, Bing, Pinterest)
   - Captures d'Ã©cran des films
   - GÃ©nÃ©ration IA (Stable Diffusion, DALL-E)
   - Datasets existants (Kaggle, etc.)
3. Recommandations:
   - Nombre d'images par personnage (200+)
   - VariÃ©tÃ© (angles, expressions, scÃ¨nes)
   - QualitÃ© (rÃ©solution, nettetÃ©)
   - Ã‰quilibre entre classes
4. Organisation:
   - Structure des dossiers
   - Nommage des fichiers
   - Split train/val/test
5. Nettoyage:
   - Supprimer duplicatas
   - VÃ©rifier la qualitÃ©
   - Labellisation correcte
6. Preprocessing:
   - Redimensionnement
   - Normalisation
   - Data augmentation
7. Outils recommandÃ©s (Python scripts, libraries)
8. Checklist de qualitÃ© du dataset
9. Exemples de commandes

Style: PÃ©dagogique, avec exemples concrets.
```

---

## ðŸ”¹ Prompt 6 â€“ Dockerfile et docker-compose

**Date**: 2025-10-15  
**Outil**: GitHub Copilot  
**Objectif**: Containerisation du projet

```
CrÃ©e un Dockerfile et docker-compose.snippet.yml pour le projet de 
reconnaissance de personnages Harry Potter. 

Dockerfile:
- Base: python:3.10-slim
- Installer dÃ©pendances systÃ¨me (libgl1-mesa-glx, libglib2.0-0)
- Copier requirements.txt et installer dÃ©pendances Python
- Copier src/, data/, models/
- Exposer port 8888 (Jupyter)
- CMD: lancer Jupyter sans token

docker-compose.snippet.yml:
- Service: character-recognition
- Ports: 8888:8888
- Volumes: src, data, models, output
- Network: poudlard-network
- Restart: unless-stopped
- Environment: PYTHONUNBUFFERED=1

Optimiser pour layer caching et build rapide.
```

---

## ðŸ”¹ Prompt 7 â€“ requirements.txt

**Date**: 2025-10-15  
**Outil**: GitHub Copilot  
**Objectif**: Lister les dÃ©pendances Python

```
GÃ©nÃ¨re un requirements.txt pour un projet de CNN avec TensorFlow/Keras. Inclure:

Core ML/DL:
- tensorflow==2.15.0
- keras==2.15.0
- numpy==1.24.3
- pandas==2.1.1
- scikit-learn==1.3.1

Image processing:
- pillow==10.1.0
- opencv-python==4.8.1.78

Visualization:
- matplotlib==3.8.0
- seaborn==0.13.0

Jupyter:
- jupyter==1.0.0
- ipykernel==6.26.0
- notebook==7.0.6

Utilities:
- tqdm==4.66.1
- pyyaml==6.0.1

Organiser par catÃ©gories avec commentaires.
```

---

## ðŸ”¹ Prompt 8 â€“ Script de test (test_smoke.sh)

**Date**: 2025-10-15  
**Outil**: GitHub Copilot  
**Objectif**: CrÃ©er le script de validation automatique

```
CrÃ©e un script bash test_smoke.sh qui vÃ©rifie:

1. Structure du projet (src/, docs/, tests/, data/, models/)
2. PrÃ©sence des fichiers essentiels:
   - README.md
   - requirements.txt
   - Dockerfile
   - docker-compose.snippet.yml
   - src/character_recognition.ipynb
   - docs/rendu.md
   - docs/prompts_used.md
3. Syntaxe Python du notebook (nbconvert --to script)
4. Installation de Python et modules clÃ©s (tensorflow, keras, numpy)
5. CrÃ©ation des rÃ©pertoires data/train, data/val, data/test
6. Docker installÃ© (optionnel)
7. Permissions des fichiers

Utiliser des couleurs (GREEN, RED, YELLOW) et des emojis.
Afficher des messages clairs pour chaque vÃ©rification.
Retourner exit code appropriÃ© (0 = succÃ¨s, 1 = Ã©chec).
Instructions finales: comment lancer le notebook.

Style: Robuste avec set -e et gestion d'erreurs.
```

---

## ðŸ”¹ Prompt 9 â€“ .gitignore

**Date**: 2025-10-15  
**Outil**: GitHub Copilot  
**Objectif**: Exclure fichiers non nÃ©cessaires du repo

```
GÃ©nÃ¨re un .gitignore pour un projet Python de deep learning. Exclure:

Python:
- __pycache__/, *.pyc, *.pyo, *.so
- venv/, env/, .venv/
- *.egg-info/, build/, dist/

Jupyter:
- .ipynb_checkpoints/

IDE:
- .vscode/, .idea/

Machine Learning:
- *.h5, *.hdf5 (sauf modÃ¨les finaux)
- models/checkpoints/
- logs/, runs/, mlruns/

Data:
- data/train/**/*.jpg
- data/val/**/*.jpg
- data/test/**/*.jpg
(garder structure avec .gitkeep)

OS:
- .DS_Store, Thumbs.db, *.swp

Docker:
- docker-compose.override.yml

Archives:
- *.zip, *.tar.gz

Garder: .gitkeep pour prÃ©server structure des dossiers
```

---

## ðŸ”¹ Prompt 10 â€“ Guide dataset (dataset_guide.md)

**Date**: 2025-10-15  
**Outil**: GitHub Copilot  
**Objectif**: Guide pratique de collecte de donnÃ©es

```
RÃ©dige un guide complet (docs/dataset_guide.md) pour crÃ©er un dataset 
d'images de personnages Harry Potter. Sections:

1. Introduction - Importance du dataset
2. Objectif - 10 personnages, 200 images chacun
3. Sources de donnÃ©es:
   - Google Images (avec filtres)
   - Bing Images
   - Pinterest
   - Captures d'Ã©cran films/sÃ©ries
   - Kaggle datasets
   - GÃ©nÃ©ration IA (Stable Diffusion, DALL-E)
4. MÃ©thodes de collecte:
   - Web scraping (BeautifulSoup, Selenium)
   - Download managers
   - Scripts Python automatisÃ©s
5. Organisation:
   - Structure folders (train/val/test)
   - Naming convention
   - Split ratio (70/15/15)
6. CritÃ¨res de qualitÃ©:
   - RÃ©solution minimum (128x128)
   - NettetÃ©, Ã©clairage
   - VariÃ©tÃ© (angles, expressions)
   - Pas de watermarks
7. Nettoyage:
   - Supprimer duplicatas (imagehash)
   - VÃ©rifier labels
   - Filtrer basse qualitÃ©
8. Preprocessing:
   - Redimensionnement uniforme
   - Augmentation (rotation, flip, crop)
9. Validation:
   - VÃ©rifier distribution
   - Tester avec modÃ¨le simple
10. Outils recommandÃ©s:
    - Python libraries (requests, PIL, opencv)
    - Scripts fournis
11. Exemples de code
12. Checklist finale

Style: Tutoriel pratique avec code et commandes.
```

---

## ðŸ“Š RÃ©sumÃ© de l'usage IA

| Composant | Prompt utilisÃ© | Outil IA | GÃ©nÃ©ration |
|-----------|---------------|----------|------------|
| Architecture projet | Prompt 1 | GitHub Copilot | Structure complÃ¨te |
| Notebook Jupyter | Prompt 2 | GitHub Copilot | Code et cellules |
| README.md | Prompt 3 | GitHub Copilot | Documentation |
| docs/rendu.md | Prompt 4 | GitHub Copilot | Rapport final |
| Dataset guide | Prompt 5, 10 | GitHub Copilot | Guide pratique |
| Dockerfile | Prompt 6 | GitHub Copilot | Configuration |
| docker-compose | Prompt 6 | GitHub Copilot | Orchestration |
| requirements.txt | Prompt 7 | GitHub Copilot | DÃ©pendances |
| test_smoke.sh | Prompt 8 | GitHub Copilot | Tests |
| .gitignore | Prompt 9 | GitHub Copilot | Exclusions |

---

## ðŸŽ¯ MÃ©thodologie d'utilisation de l'IA

1. **Planification** - DÃ©finir structure et objectifs avant gÃ©nÃ©ration
2. **Prompts dÃ©taillÃ©s** - SpÃ©cifier tous les dÃ©tails attendus
3. **ItÃ©ration** - Affiner les prompts selon rÃ©sultats
4. **Validation** - VÃ©rifier le code gÃ©nÃ©rÃ©, tester
5. **Personnalisation** - Adapter aux besoins spÃ©cifiques du projet
6. **Documentation** - Archiver tous les prompts utilisÃ©s

---

## ðŸ’¡ Bonnes pratiques identifiÃ©es

âœ… **Prompts structurÃ©s** - Utiliser listes numÃ©rotÃ©es pour clartÃ©  
âœ… **Contexte explicite** - Mentionner framework, versions, conventions  
âœ… **Exemples concrets** - Donner des exemples de sortie attendue  
âœ… **Style dÃ©fini** - SpÃ©cifier ton, format, emojis  
âœ… **Contraintes claires** - PrÃ©ciser limites et exigences  
âœ… **Validation humaine** - Toujours vÃ©rifier et tester le code gÃ©nÃ©rÃ©  

---

> ðŸ¤– *"Intelligence Artificielle, c'est bien. Intelligence Humaine + IA, c'est magique!"*
