# ğŸš€ LE NIMBUS 3000 - Optimizer Benchmark

Benchmark rigoureux des principaux optimizers sur un modÃ¨le CNN de reconnaissance de personnages Harry Potter.

## ğŸ¯ Objectif

Comparer systÃ©matiquement les performances de 8 optimizers diffÃ©rents:
- **SGD** (avec/sans momentum, Nesterov)
- **Adam**
- **AdamW** 
- **RMSProp**
- **Adagrad**
- **Adadelta**
- **Adan**

## ğŸ“¦ Livrables

- ğŸ“˜ **Rapport acadÃ©mique** (PDF) dans `reports/paper.pdf`
- ğŸ§ª **Scripts de reproduction** dans `scripts/`
- ğŸ“Š **RÃ©sultats et figures** dans `reports/figures/`

## ğŸ—ï¸ Architecture

```
21-nimbus-3000/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Dataset brut
â”‚   â””â”€â”€ processed/        # DonnÃ©es prÃ©traitÃ©es
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ net.py        # Architecture CNN
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â””â”€â”€ loader.py     # DataLoaders
â”‚   â”œâ”€â”€ train.py          # Script d'entraÃ®nement
â”‚   â”œâ”€â”€ eval.py           # Ã‰valuation
â”‚   â”œâ”€â”€ utils.py          # Utilitaires
â”‚   â””â”€â”€ optim_space.py    # Grilles d'hyperparamÃ¨tres
â”œâ”€â”€ runs/
â”‚   â””â”€â”€ logs/             # Logs d'entraÃ®nement
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/          # Graphiques
â”‚   â”œâ”€â”€ tables/           # Tableaux de rÃ©sultats
â”‚   â””â”€â”€ paper.md          # Rapport en Markdown
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_grid.sh       # Lance tous les benchmarks
â”‚   â”œâ”€â”€ summarize.py      # AgrÃ¨ge les rÃ©sultats
â”‚   â””â”€â”€ plot_curves.py    # GÃ©nÃ¨re les figures
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ smoke_test.sh     # Test de fumÃ©e
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ“‹ PrÃ©requis

- Python 3.10+
- PyTorch 2.1+
- 8GB+ RAM
- GPU recommandÃ© (CUDA 11.8+)

## ğŸš€ Installation

```bash
cd projects/21-nimbus-3000

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## ğŸ“Š Dataset

Le benchmark utilise le dataset du dÃ©fi "Is it you Harry" (10 personnages, ~2000 images).

Structure:
```
data/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
```

## ğŸ“ Utilisation

### 1. Lancer un entraÃ®nement unique

```bash
python src/train.py \
  --optimizer adamw \
  --lr 0.001 \
  --epochs 50 \
  --seed 42 \
  --batch-size 64
```

### 2. Lancer tous les benchmarks

```bash
bash scripts/run_grid.sh
```

Cela exÃ©cute:
- Tous les optimizers avec leurs grilles d'hyperparamÃ¨tres
- 5 seeds diffÃ©rents par configuration
- Logging automatique dans `runs/logs/`

### 3. AgrÃ©ger les rÃ©sultats

```bash
python scripts/summarize.py \
  --runs runs/logs \
  --out reports/tables/summary.csv
```

### 4. GÃ©nÃ©rer les figures

```bash
python scripts/plot_curves.py \
  --in reports/tables/summary.csv \
  --out reports/figures
```

## ğŸ“ˆ MÃ©triques mesurÃ©es

- **Accuracy** (train/val/test)
- **F1-Score** (macro)
- **Loss** (CrossEntropy)
- **Temps par epoch**
- **Temps total d'entraÃ®nement**
- **Utilisation mÃ©moire GPU**

## âš™ï¸ Configuration expÃ©rimentale

### Protocole commun Ã  tous les optimizers

- **Epochs**: 50 (early stopping patience=10)
- **Batch size**: 64
- **Image size**: 128x128
- **Data augmentation**: rotation, flip, crop
- **Split**: 70/15/15 (train/val/test)
- **Seeds**: [42, 123, 456, 789, 1024]
- **Scheduler**: CosineAnnealingLR
- **Weight decay**: variable selon optimizer
- **Gradient clipping**: 1.0

### Grilles d'hyperparamÃ¨tres

Voir `src/optim_space.py` pour les dÃ©tails.

Exemples:
- **SGD**: lr âˆˆ {0.1, 0.01}, momentum âˆˆ {0, 0.9}
- **Adam**: lr âˆˆ {1e-3, 3e-4}, betas âˆˆ {(0.9,0.999), (0.9,0.95)}
- **AdamW**: lr âˆˆ {1e-3, 3e-4}, weight_decay âˆˆ {0.01, 0.05}

## ğŸ§ª Tests

```bash
# Test de fumÃ©e (1 epoch, petit subset)
bash tests/smoke_test.sh
```

## ğŸ“š Rapport acadÃ©mique

Structure du rapport (`reports/paper.md`):

1. RÃ©sumÃ©
2. Introduction
3. Travaux connexes
4. MÃ©thodologie
5. RÃ©sultats
6. Analyse
7. Limites
8. Conclusion
9. Annexes

## ğŸ”§ Technologies utilisÃ©es

- **PyTorch** - Framework deep learning
- **torchvision** - Vision utilities
- **adan-pytorch** - Adan optimizer
- **matplotlib/seaborn** - Visualisations
- **pandas** - Manipulation de donnÃ©es
- **wandb** - Tracking expÃ©rimental (optionnel)

## ğŸ“Š RÃ©sultats attendus

Les rÃ©sultats complets sont dans `reports/`:
- Tableaux comparatifs (moyenne Â± Ã©cart-type)
- Courbes de convergence
- Tests statistiques (t-test, ANOVA)
- Analyse coÃ»t/performance

## ğŸ’¡ ReproductibilitÃ©

- Seeds fixÃ©s: [42, 123, 456, 789, 1024]
- Versions documentÃ©es (PyTorch, CUDA, cuDNN)
- Configs sauvegardÃ©es dans `runs/logs/config_*.yaml`
- Logs dÃ©taillÃ©s par epoch

## ğŸ‘¥ Copilots

- ğŸ§  **AI Copilot** (lead) - Architecture et code
- ğŸ“Š **Data Copilot** - Analyse et rapport

## ğŸ“ Licence

Projet Ã©ducatif - Workshop Poudlard EPSI

---

> ğŸ§¹ *"The Nimbus 3000 may be fast, but which optimizer is faster?"*
