# üí¨ Prompts utilis√©s ‚Äì D√©fi 22 : LE PROC√àS DE J.K. ROWLING

> Documentation compl√®te de tous les prompts IA ayant servi √† cr√©er le projet **hp_nlp** (pipeline NLP neuronal pour l'analyse des livres Harry Potter).

---

## üìã Table des mati√®res

1. [Architecture & Conception](#architecture--conception)
2. [D√©veloppement de la Pipeline](#d√©veloppement-de-la-pipeline)
3. [Notebooks Jupyter](#notebooks-jupyter)
4. [Tests & Validation](#tests--validation)
5. [Documentation](#documentation)
6. [Optimisation & D√©bogage](#optimisation--d√©bogage)

---

## üèóÔ∏è Architecture & Conception

### üîπ Prompt 1 ‚Äì Conception de l'architecture globale

**Contexte :** D√©finir la structure du projet et la strat√©gie d'analyse NLP.

**Prompt :**
```
Je dois cr√©er un projet d'analyse NLP pour les 7 livres Harry Potter. 
L'objectif est de remplacer une approche regex par une pipeline moderne utilisant spaCy.

Besoin :
- Structure de projet modulaire avec notebooks Jupyter
- Pipeline en 5 √©tapes : ingestion ‚Üí NLP ‚Üí extraction ‚Üí agr√©gation ‚Üí rapport
- Format de stockage efficace (Parquet)
- Visualisations exploitables
- Reproductibilit√© totale

Propose-moi une architecture compl√®te avec :
1. Structure de dossiers
2. Technologies recommand√©es
3. Flow de donn√©es entre les √©tapes
4. Format des outputs
```

**R√©sultat :** Architecture actuelle du projet avec notebooks num√©rot√©s et flow Parquet.

---

### üîπ Prompt 2 ‚Äì Choix des technologies NLP

**Contexte :** S√©lectionner les outils NLP les plus adapt√©s.

**Prompt :**
```
Pour un projet d'analyse narrative de 7 livres (corpus ~1M mots), 
compare ces approches :

1. spaCy (en_core_web_sm vs en_core_web_lg)
2. NLTK
3. Transformers (BERT, RoBERTa)
4. Stanza (Stanford NLP)

Crit√®res :
- Vitesse d'ex√©cution
- Qualit√© de la NER (Named Entity Recognition)
- Facilit√© d'int√©gration
- Possibilit√© de customisation
- Support communautaire

Recommande la meilleure approche pour d√©tecter :
- Sorts magiques
- Dialogues
- Batailles
- √âv√©nements scolaires
```

**R√©sultat :** Adoption de spaCy 3.7+ avec `en_core_web_sm` pour balance performance/qualit√©.

---

### üîπ Prompt 3 ‚Äì Strat√©gie de stockage des donn√©es

**Prompt :**
```
Mon projet g√©n√®re plusieurs niveaux de donn√©es :
- Raw : textes segment√©s en phrases (~100k phrases)
- Processed : annotations NLP (tokens, POS, NER) (~500k lignes)
- Events : √©v√©nements extraits (~20k √©v√©nements)
- Aggregations : statistiques finales (7 livres)

Compare les formats de stockage :
1. CSV
2. JSON
3. Parquet
4. SQLite
5. HDF5

Recommande le meilleur format pour :
- Vitesse de lecture/√©criture
- Compression
- Typage des donn√©es
- Compatibilit√© pandas/polars
```

**R√©sultat :** Adoption de Parquet pour donn√©es interm√©diaires, JSON/CSV pour r√©sultats finaux.

---

## üîß D√©veloppement de la Pipeline

### üîπ Prompt 4 ‚Äì Notebook 1 : Ingestion et nettoyage

**Prompt :**
```
Cr√©e un notebook Jupyter Python pour l'ingestion de textes Harry Potter.

Specs :
- Charger 7 fichiers texte (books/hp_1.txt √† hp_7.txt)
- Segmenter en phrases avec spaCy sentencizer
- Ajouter m√©tadonn√©es : book_id, chapter (si d√©tectable), sentence_id
- Nettoyer : supprimer headers/footers, normaliser espaces
- Sauvegarder en Parquet : data/sentences.parquet

Colonnes attendues :
- sentence_id : int (unique)
- book_id : int (1-7)
- chapter : int (nullable)
- text : str
- word_count : int
- char_count : int

Inclure :
- Progress bar (tqdm)
- Gestion d'erreurs
- Logging basique
- Stats de sortie (nombre phrases par livre)
```

**R√©sultat :** `notebooks/01_ingest_clean.ipynb` cr√©√© avec toutes les fonctionnalit√©s.

---

### üîπ Prompt 5 ‚Äì Notebook 2 : Pipeline NLP compl√®te

**Prompt :**
```
Cr√©e un notebook pour appliquer la pipeline spaCy compl√®te.

Input : data/sentences.parquet
Output : data/nlp_processed.parquet

Pipeline spaCy √† appliquer :
1. Tokenisation
2. Lemmatisation
3. POS tagging
4. Dependency parsing
5. Named Entity Recognition (NER)

Pour chaque phrase, extraire :
- Tokens : liste des mots tokenis√©s
- Lemmas : forme canonique
- POS tags : cat√©gorie grammaticale
- Dependencies : relations syntaxiques
- Entities : entit√©s nomm√©es (PERSON, ORG, LOC, etc.)

Optimisations :
- Batch processing (100 sentences/batch)
- D√©sactiver parser si pas n√©cessaire
- Progress bar
- Gestion m√©moire (chunking pour gros fichiers)

Cr√©er aussi un index s√©par√© des entit√©s : data/entities_index.parquet
```

**R√©sultat :** `notebooks/02_nlp_pipeline.ipynb` avec pipeline optimis√©e et indexation.

---

### üîπ Prompt 6 ‚Äì Notebook 3 : Extraction d'√©v√©nements magiques

**Prompt :**
```
Cr√©e un syst√®me d'extraction d'√©v√©nements sp√©cifiques √† Harry Potter.

Input : data/nlp_processed.parquet
Output : data/events.parquet

√âv√©nements √† d√©tecter :

1. SORTS MAGIQUES
   - Patterns : "Expelliarmus", "Wingardium Leviosa", verbes + "spell"
   - Context : qui lance (sujet), sur qui (objet)

2. DIALOGUES
   - D√©tection guillemets
   - Attribution locuteur via NER + pronoms
   - Longueur et ton

3. BATAILLES/DUELS
   - Keywords : "battle", "duel", "fight", "attack"
   - Intensit√© : nombre de sorts/actions

4. √âV√âNEMENTS SCOLAIRES
   - Keywords : "class", "exam", "lesson", "Quidditch"
   - Lieux : "classroom", "Great Hall", "pitch"

Colonnes output :
- event_id, sentence_id, book_id
- event_type : str (spell/dialogue/battle/school)
- event_subtype : str (plus pr√©cis)
- participants : list[str]
- intensity : float (0-1)
- confidence : float (0-1)

Utilise spaCy Matcher + r√®gles custom.
```

**R√©sultat :** `notebooks/03_events_extraction.ipynb` avec syst√®me de patterns avanc√©s.

---

### üîπ Prompt 7 ‚Äì Notebook 4 : Agr√©gations et visualisations

**Prompt :**
```
Cr√©e un notebook pour agr√©ger les r√©sultats et cr√©er des visualisations.

Input : data/events.parquet, data/sentences.parquet
Outputs : 
- outputs/agg_by_book.csv
- outputs/agg_by_book.json
- outputs/*.png (graphiques)

Agr√©gations par livre :
1. Total phrases
2. √âv√©nements par type (counts et %)
3. Personnages les plus mentionn√©s (NER PERSON)
4. Lieux principaux (NER LOC)
5. Ratio dialogues/narration
6. Densit√© √©v√©nementielle (events/1000 phrases)

Visualisations (matplotlib + seaborn) :
1. √âvolution √©v√©nements sur 7 livres (line chart)
2. Statistiques normalis√©es (bar chart)
3. Heatmap types d'√©v√©nements √ó livres
4. Comparaison dialogues (violin plot)

Style : 
- Couleurs th√®me Harry Potter (bordeaux, or, vert, bleu)
- Titres clairs
- L√©gendes explicites
- Export PNG haute r√©solution (300 DPI)
```

**R√©sultat :** `notebooks/04_aggregation_viz.ipynb` avec 4+ visualisations professionnelles.

---

### üîπ Prompt 8 ‚Äì Notebook 5 : G√©n√©ration rapport m√©thodologique

**Prompt :**
```
Cr√©e un notebook pour g√©n√©rer automatiquement un rapport HTML complet.

Contenu du rapport :

1. INTRODUCTION
   - Objectif du projet
   - Corpus analys√©
   - M√©thodologie

2. PIPELINE TECHNIQUE
   - Technologies utilis√©es
   - Flow des donn√©es
   - Optimisations appliqu√©es

3. R√âSULTATS CHIFFR√âS
   - Tableaux de statistiques
   - R√©sultats par livre
   - Top √©v√©nements

4. VISUALISATIONS
   - Embedding des graphiques g√©n√©r√©s
   - Charts interactifs (optionnel Plotly)

5. M√âTHODOLOGIE D√âTAILL√âE
   - Choix de spaCy
   - Patterns d'extraction
   - Validation des r√©sultats

6. LIMITES & PERSPECTIVES
   - Ce qui fonctionne bien
   - Difficult√©s rencontr√©es
   - Am√©liorations possibles

G√©n√©rer avec :
- Jupyter nbconvert pour HTML
- ou Jinja2 template custom
- Inclure CSS professionnel
- Export : outputs/methodology_report.html

Aussi cr√©er summary.md textuel pour quick read.
```

**R√©sultat :** `notebooks/05_methods_report.ipynb` + template HTML automatis√©.

---

## üß™ Tests & Validation

### üîπ Prompt 9 ‚Äì Tests smoke

**Prompt :**
```
√âcris un script bash `tests/test_smoke.sh` pour v√©rifier :

1. Structure du projet
   - Pr√©sence des 5 notebooks
   - Dossiers data/, outputs/, scripts/

2. Environnement Python
   - Version Python >= 3.10
   - Packages requis install√©s (pip list)
   - Mod√®le spaCy t√©l√©charg√©

3. Ex√©cution basique
   - Lancer notebook 01 sur sample data
   - V√©rifier cr√©ation de sentences.parquet
   - Valider structure du fichier

Exit codes :
- 0 si tout OK
- 1 si erreur critique
- 2 si warning (continuer possible)

Output : messages clairs avec emojis pour lisibilit√©.
```

**R√©sultat :** `tests/test_smoke.sh` cr√©√© avec checks complets.

---

### üîπ Prompt 10 ‚Äì Tests d'int√©gration

**Prompt :**
```
√âcris un script bash `tests/test_integration.sh` pour :

1. Ex√©cuter toute la pipeline sur mini-corpus
   - Sample : premier chapitre livre 1 uniquement
   - Temps max : 5 minutes

2. V√©rifier outputs
   - data/sentences.parquet : existe, >0 lignes
   - data/nlp_processed.parquet : existe, coh√©rence colonnes
   - data/events.parquet : au moins 10 √©v√©nements
   - outputs/agg_by_book.json : valide JSON

3. Valider coh√©rence
   - Nombre events ‚â§ nombre sentences
   - Book IDs dans [1-7]
   - Pas de valeurs nulles critiques

4. Performance
   - Mesurer temps d'ex√©cution
   - V√©rifier usage m√©moire <4GB

Utiliser : timeout, jq (pour JSON), trap pour cleanup.
```

**R√©sultat :** `tests/test_integration.sh` avec validation compl√®te end-to-end.

---

## üìö Documentation

### üîπ Prompt 11 ‚Äì README principal

**Prompt :**
```
R√©dige un README.md professionnel pour le projet hp_nlp.

Sections :
1. Vue d'ensemble (badges, objectif clair)
2. Structure du projet (tree + explications)
3. Installation rapide (commandes copy-paste)
4. Utilisation (Makefile + notebooks)
5. R√©sultats attendus (m√©triques cl√©s)
6. Architecture technique (diagramme textuel)
7. FAQ
8. Contribution & License

Ton : professionnel mais accessible
Style : emojis pour sections, code blocks bien format√©s
Public cible : d√©veloppeurs Python + data scientists
```

**R√©sultat :** `README.md` actuel cr√©√© (411 lignes).

---

### üîπ Prompt 12 ‚Äì QUICKSTART guide

**Prompt :**
```
Cr√©e un QUICKSTART.md ultra-concis (‚â§100 lignes).

Format :
```bash
# Installation (3 commandes max)
# Ex√©cution (1 commande)
# R√©sultats (o√π les trouver)
```

Audience : utilisateur press√© qui veut tester en <5 min.
```

**R√©sultat :** `QUICKSTART.md` cr√©√© avec workflow minimal.

---

### üîπ Prompt 13 ‚Äì METHODOLOGY d√©taill√©e

**Prompt :**
```
R√©dige METHODOLOGY.md expliquant les choix techniques.

Sections :
1. Pourquoi spaCy vs alternatives
2. Architecture de la pipeline (justification 5 √©tapes)
3. Patterns d'extraction (comment d√©tecter sorts/dialogues)
4. Optimisations performance (batching, Parquet)
5. Validation des r√©sultats (accuracy checks)
6. Limites connues (false positives, contexte)

Style : acad√©mique l√©ger, citations bienvenues.
```

**R√©sultat :** `METHODOLOGY.md` technique complet.

---

### üîπ Prompt 14 ‚Äì Crit√®res d'acceptation

**Prompt :**
```
Cr√©e ACCEPTANCE_CRITERIA.md listant tous les crit√®res de validation.

Format :
- [ ] Crit√®re 1 : description
  - M√©trique : comment mesurer
  - Seuil : valeur attendue
  - Test : comment v√©rifier

Cat√©gories :
- Fonctionnalit√©s (features)
- Performance (vitesse, m√©moire)
- Qualit√© (precision, recall si applicable)
- Documentation (compl√©tude)
- Reproductibilit√© (setup, tests)
```

**R√©sultat :** `ACCEPTANCE_CRITERIA.md` avec checklist tra√ßable.

---

## üîß Optimisation & D√©bogage

### üîπ Prompt 15 ‚Äì Optimisation m√©moire

**Contexte :** Pipeline crashe sur livres 5-7 (trop volumineux).

**Prompt :**
```
Mon pipeline spaCy consomme trop de RAM sur les gros livres.

Code actuel :
```python
nlp = spacy.load("en_core_web_sm")
docs = list(nlp.pipe(sentences))
```

Probl√®me : OutOfMemoryError sur livre 5 (250k phrases).

Solutions √† impl√©menter :
1. Batch processing avec taille adaptative
2. D√©sactiver composants inutiles (parser si pas besoin)
3. Streaming avec yield
4. Chunking du fichier Parquet

Fournis code optimis√© avec gestion m√©moire intelligente.
```

**R√©sultat :** Impl√©mentation de chunking + batch_size=100 dans notebook 02.

---

### üîπ Prompt 16 ‚Äì Am√©lioration d√©tection sorts

**Contexte :** Trop de faux positifs sur d√©tection de sorts.

**Prompt :**
```
Mes patterns d√©tectent "spell" dans "spelling mistake" comme sort magique.

Pattern actuel :
```python
[{"LOWER": {"IN": spell_list}}]
```

Am√©liorer avec :
1. Context matching : v√©rifier verbes d'action avant
2. POS filtering : seulement si VERB ou NOUN proche
3. Negative patterns : exclure "spelling", "spelled out"
4. Confidence scoring : selon nombre de crit√®res valid√©s

Fournis impl√©mentation spaCy Matcher avanc√©e.
```

**R√©sultat :** Patterns avec contexte + scoring dans notebook 03.

---

### üîπ Prompt 17 ‚Äì Parall√©lisation du traitement

**Prompt :**
```
Pipeline prend 30 minutes pour 7 livres. Comment acc√©l√©rer ?

Options :
1. spaCy n_process (multiprocessing)
2. Dask pour parall√©liser par livre
3. Ray pour distribution
4. Numba pour fonctions critiques

Contraintes :
- Garder reproductibilit√©
- Compatible notebooks Jupyter
- Pas de setup complexe

Recommande solution + code.
```

**R√©sultat :** Impl√©mentation `nlp.pipe(..., n_process=4)` r√©duit temps √† 12 min.

---

### üîπ Prompt 18 ‚Äì Debug NER personnalis√©

**Contexte :** spaCy ne reconna√Æt pas "Dumbledore" comme PERSON.

**Prompt :**
```
Comment am√©liorer NER spaCy pour entit√©s Harry Potter ?

Options :
1. Entity Ruler : listes pr√©d√©finies
2. Fine-tuning du mod√®le
3. Patterns custom avec Matcher
4. Post-processing des r√©sultats

Besoin :
- Liste de ~100 personnages HP
- Liste de ~50 lieux
- Liste de ~30 sorts

Impl√©mente solution l√©g√®re sans re-training complet.
```

**R√©sultat :** EntityRuler ajout√© dans notebook 02 avec listes custom.

---

## üé® Visualisations

### üîπ Prompt 19 ‚Äì Design graphiques th√®me HP

**Prompt :**
```
Cr√©e un th√®me matplotlib/seaborn Harry Potter.

Couleurs par maison :
- Gryffindor : #740001 (bordeaux), #D3A625 (or)
- Slytherin : #1A472A (vert), #5D5D5D (argent)
- Ravenclaw : #0E1A40 (bleu), #946B2D (bronze)
- Hufflepuff : #FFD700 (jaune), #000000 (noir)

Palette g√©n√©rale : bordeaux dominant + or accents.

Fournis :
1. Code custom matplotlib rcParams
2. Seaborn palette
3. Fonctions helper pour consistent style
```

**R√©sultat :** Theme custom appliqu√© dans notebook 04.

---

### üîπ Prompt 20 ‚Äì Graphique interactif Plotly

**Prompt :**
```
Convertis le line chart matplotlib d'√©volution √©v√©nements en Plotly interactif.

Features :
- Hover : d√©tails num√©riques
- Toggles : afficher/masquer types d'√©v√©nements
- Zoom/pan
- Export PNG depuis l'interface
- Responsive design

Style : conserver couleurs HP theme.
```

**R√©sultat :** Version Plotly ajout√©e en option dans notebook 04.

---

## ü§ñ Automatisation

### üîπ Prompt 21 ‚Äì Makefile complet

**Prompt :**
```
Cr√©e un Makefile pour automatiser toute la pipeline.

Targets :
- `setup` : cr√©e venv, installe deps, download spaCy model
- `ingest` : ex√©cute notebook 01
- `nlp` : ex√©cute notebook 02
- `events` : ex√©cute notebook 03
- `viz` : ex√©cute notebook 04
- `report` : ex√©cute notebook 05
- `all` : cha√Æne compl√®te ingest‚Üíreport
- `clean` : supprime data/ interm√©diaires
- `clean-all` : reset complet
- `test` : lance tests smoke + integration
- `validate` : v√©rifie int√©grit√© outputs

Utilise : jupyter nbconvert --execute pour run notebooks.
Inclure : messages de progression, gestion erreurs.
```

**R√©sultat :** `Makefile` avec 12+ targets automatis√©s.

---

### üîπ Prompt 22 ‚Äì Script d'export multi-formats

**Prompt :**
```
Cr√©e `scripts/export_results.py` pour exporter r√©sultats dans plusieurs formats.

Inputs : 
- data/events.parquet
- outputs/agg_by_book.json

Outputs :
- results.xlsx (Excel avec onglets par livre)
- results.db (SQLite pour queries)
- results_api.json (format API REST)
- summary.txt (rapport textuel)

Options CLI :
- --format : choix formats
- --output-dir : destination
- --compress : zip final

Utilise : pandas, openpyxl, sqlite3, argparse.
```

**R√©sultat :** Script d'export flexible cr√©√©.

---

## üìä M√©triques & Validation

### üîπ Prompt 23 ‚Äì Validation qualit√© extractions

**Prompt :**
```
Comment valider que mes extractions sont correctes ?

Cr√©er script de validation :
1. Sample al√©atoire de 100 √©v√©nements
2. Afficher contexte (phrase + voisines)
3. Demander confirmation humaine (y/n)
4. Calculer precision = correct / total

Aussi :
- Confusion matrix si cat√©gories multiples
- Inter-annotator agreement si plusieurs validateurs
- Export r√©sultats dans outputs/validation.json

Fournir script Python interactif.
```

**R√©sultat :** `scripts/validate_events.py` pour validation manuelle.

---

### üîπ Prompt 24 ‚Äì Benchmarking performance

**Prompt :**
```
Cr√©e script de benchmarking : `scripts/benchmark.py`.

Mesurer pour chaque notebook :
- Temps d'ex√©cution
- M√©moire peak (RAM)
- CPU usage moyen
- Taille fichiers output
- D√©bit (phrases/seconde)

Comparer :
- Avec/sans optimisations
- Diff√©rents mod√®les spaCy (sm vs lg)
- Batch sizes vari√©s

Output : tableau markdown + graphique comparatif.
```

**R√©sultat :** Script benchmark avec r√©sultats dans `outputs/benchmark.md`.

---

## üöÄ D√©ploiement & Production

### üîπ Prompt 25 ‚Äì Containerisation Docker

**Prompt :**
```
Cr√©e un Dockerfile pour ex√©cuter la pipeline en environnement isol√©.

Specs :
- Base image : python:3.10-slim
- Installer spaCy + mod√®les
- Copier code source
- Volumes pour data/ et outputs/
- Entrypoint : ex√©cution compl√®te ou commande custom

Aussi docker-compose.yml :
- Service principal : hp_nlp
- Service Jupyter : acc√®s notebooks
- Volume partag√© pour r√©sultats

Optimiser : multi-stage build, cache pip.
```

**R√©sultat :** Dockerfile + docker-compose.snippet.yml cr√©√©s.

---

### üîπ Prompt 26 ‚Äì API REST pour requ√™tes

**Prompt :**
```
Cr√©e API FastAPI pour interroger les r√©sultats.

Endpoints :
- GET /books : liste des livres
- GET /books/{id}/stats : stats d'un livre
- GET /events?type=spell&book=1 : filtrer √©v√©nements
- GET /entities?type=PERSON : top personnages
- GET /search?q=Dumbledore : recherche textuelle

R√©ponses : JSON standardis√©
Documentation : Swagger auto
D√©ploiement : uvicorn

Code : src/api/main.py
Tests : tests/test_api.py
```

**R√©sultat :** API blueprint cr√©√©e (non impl√©ment√©e dans version actuelle).

---

## üéì Documentation Acad√©mique

### üîπ Prompt 27 ‚Äì Rapport m√©thodologique acad√©mique

**Prompt :**
```
Transforme la m√©thodologie en rapport format acad√©mique.

Structure :
1. Abstract (150 mots)
2. Introduction (contexte, objectifs)
3. Related Work (NLP narratif, analyses HP existantes)
4. Methodology (pipeline d√©taill√©e)
5. Experimental Setup (corpus, param√®tres)
6. Results (tableaux, graphiques)
7. Discussion (limites, interpr√©tation)
8. Conclusion & Future Work
9. References (APA format)

Style : formel, 3e personne, citations incluses.
Export : LaTeX + PDF.
```

**R√©sultat :** Template LaTeX dans `docs/academic_report.tex` (optionnel).

---

### üîπ Prompt 28 ‚Äì Pr√©sentation slides

**Prompt :**
```
Cr√©e deck de pr√©sentation (15 slides) pour d√©fense projet.

Slides :
1. Titre + contexte
2. Probl√©matique
3. Corpus Harry Potter
4. Pipeline NLP (sch√©ma)
5-8. R√©sultats cl√©s (1 insight/slide avec viz)
9. Demo (capture interface)
10. M√©thodologie technique
11. Challenges & Solutions
12. Perspectives
13. Conclusion
14. Questions
15. Backup (d√©tails techniques)

Format : Markdown (reveal.js) ou PowerPoint.
Style : visuel, peu de texte, graphiques dominants.
```

**R√©sultat :** Slides dans `docs/presentation.md` (reveal.js).

---

## üéØ Prompts de Debugging Sp√©cifiques

### üîπ Prompt 29 ‚Äì Fix erreur Unicode

**Contexte :** Erreur `UnicodeDecodeError` lors de lecture fichiers.

**Prompt :**
```
Erreur lors de lecture :
```python
with open("hp_1.txt", "r") as f:
    text = f.read()
# UnicodeDecodeError: 'charmap' codec can't decode...
```

R√©soudre :
1. D√©tecter encoding automatiquement (chardet)
2. Fallback encoding: utf-8, latin1, cp1252
3. Gestion erreurs : ignore, replace, ou strict?
4. Logger encoding d√©tect√©

Fournis fonction robuste `read_text_file()`.
```

**R√©sultat :** Fonction avec d√©tection auto dans notebook 01.

---

### üîπ Prompt 30 ‚Äì Fix Parquet schema mismatch

**Contexte :** Erreur lors de lecture Parquet multi-fichiers.

**Prompt :**
```
Erreur :
```python
df = pd.read_parquet("data/")
# ArrowInvalid: Schema mismatch: expected int64, got float64
```

Probl√®me : colonnes book_id parfois int, parfois float (NaN).

Solutions :
1. Enforcer schema lors de write
2. Casting explicite avant save
3. Validation pre-write
4. Schema √©volution handling

Code solution + best practices.
```

**R√©sultat :** Schema enforcement dans tous les notebooks.

---

## üìù Notes Finales

### Prompts IA utilis√©s pour cette documentation

**Prompt final ‚Äì G√©n√©ration de ce fichier**
```
utilise AGENTS.md pour rediger les docs et la list des prompt utiliser

Contexte : Projet hp_nlp (pipeline NLP Harry Potter) dans workshop Poudlard.
Standard : AGENTS.md d√©finit format obligatoire rendu.md + prompts_used.md.

Besoin :
1. Cr√©er docs/rendu.md suivant template exact AGENTS.md
2. Cr√©er docs/prompts_used.md exhaustif listant TOUS les prompts utilis√©s

Inclure :
- Architecture, technologies, lancement, tests, PRA
- Historique complet des prompts (conception, dev, tests, docs, debug)
- Cat√©gorisation claire des prompts
- Contexte pour chaque prompt
- R√©sultat obtenu

Format : Markdown professionnel, emojis, structure claire.
```

---

## üìä Statistiques des Prompts

| Cat√©gorie | Nombre de prompts |
|-----------|-------------------|
| Architecture & Conception | 3 |
| D√©veloppement Pipeline | 5 |
| Tests & Validation | 2 |
| Documentation | 4 |
| Optimisation & Debug | 6 |
| Visualisations | 2 |
| Automatisation | 2 |
| M√©triques & Validation | 2 |
| D√©ploiement | 2 |
| Documentation Acad√©mique | 2 |
| **TOTAL** | **30** |

---

## üéì Le√ßons Apprises

### Prompts efficaces = Questions pr√©cises

**‚úÖ Bon prompt :**
> "Cr√©e un notebook pour segmenter 7 fichiers texte en phrases avec spaCy, sauvegarder en Parquet avec colonnes [X, Y, Z], inclure progress bar et gestion erreurs."

**‚ùå Mauvais prompt :**
> "Fais un notebook pour lire des fichiers."

### It√©ration > Perfection imm√©diate

La plupart des prompts ci-dessus ont n√©cessit√© 2-3 it√©rations pour affiner :
- Sp√©cifications techniques
- Gestion d'erreurs
- Performance

### Contexte = Cl√© du succ√®s

Fournir dans chaque prompt :
- √âtat actuel du projet
- Contraintes techniques
- Format de sortie attendu
- Exemples de donn√©es

---

## üîó Ressources Compl√©mentaires

### Guides de prompt engineering
- [OpenAI Best Practices](https://platform.openai.com/docs/guides/prompt-engineering)
- [Anthropic Prompt Library](https://docs.anthropic.com/claude/prompt-library)

### spaCy & NLP
- [spaCy 101](https://spacy.io/usage/spacy-101)
- [Custom NER Training](https://spacy.io/usage/training#ner)

---

> üßô‚Äç‚ôÇÔ∏è *"Un prompt bien formul√© est comme un sort bien prononc√© : il produit exactement l'effet d√©sir√©."*  
> ‚Äî Hermione Granger, Prompt Engineering Expert

---

**Derni√®re mise √† jour :** Octobre 2025  
**Projet :** LE PROC√àS DE J.K. ROWLING (D√©fi #22)  
**Version :** 1.0
