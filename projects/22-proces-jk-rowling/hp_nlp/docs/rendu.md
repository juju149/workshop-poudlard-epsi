# ðŸ§¾ Rendu â€“ LE PROCÃˆS DE J.K. ROWLING (DÃ©fi 22)

## ðŸŽ¯ Objectif

CrÃ©er une pipeline NLP neuronal complÃ¨te pour analyser les 7 livres Harry Potter et extraire automatiquement des Ã©vÃ©nements, statistiques et insights narratifs, en remplaÃ§ant l'approche regex par des techniques modernes de traitement du langage naturel (spaCy, deep learning).

---

## ðŸ§© Architecture

### Modules principaux

1. **Ingestion et nettoyage** (`01_ingest_clean.ipynb`)
   - Chargement des textes bruts
   - Segmentation en phrases
   - Nettoyage et normalisation

2. **Pipeline NLP** (`02_nlp_pipeline.ipynb`)
   - Tokenisation avec spaCy
   - POS tagging (Part-of-Speech)
   - Named Entity Recognition (NER)
   - Extraction de dÃ©pendances syntaxiques

3. **Extraction d'Ã©vÃ©nements** (`03_events_extraction.ipynb`)
   - DÃ©tection de sorts magiques
   - Identification de dialogues
   - Extraction de batailles et duels
   - Reconnaissance d'Ã©vÃ©nements scolaires

4. **AgrÃ©gation et visualisation** (`04_aggregation_viz.ipynb`)
   - Statistiques par livre
   - Ã‰volution temporelle des Ã©vÃ©nements
   - Graphiques interactifs
   - Heatmaps et comparaisons

5. **GÃ©nÃ©ration de rapport** (`05_methods_report.ipynb`)
   - Rapport mÃ©thodologique HTML automatique
   - Export JSON/CSV des rÃ©sultats
   - RÃ©sumÃ© exÃ©cutif

### Structure de donnÃ©es

```
Data Flow:
Textes bruts â†’ sentences.parquet â†’ nlp_processed.parquet â†’ events.parquet â†’ AgrÃ©gations finales
                                  â†“
                        entities_index.parquet
```

### Fichiers de sortie

- `agg_by_book.csv` / `.json` : statistiques agrÃ©gÃ©es par livre
- `methodology_report.html` : rapport complet avec mÃ©thodologie
- `summary.md` : rÃ©sumÃ© textuel des rÃ©sultats
- Graphiques PNG : Ã©volutions, comparaisons, heatmaps

---

## âš™ï¸ Technologies utilisÃ©es

### Core
- **Python 3.10+**
- **Jupyter Notebooks** : reproductibilitÃ© et documentation interactive

### NLP & ML
- **spaCy 3.7+** : pipeline NLP (tokenisation, POS, NER)
- **spaCy Transformers** : modÃ¨les avancÃ©s (optionnel)
- **en_core_web_sm/lg** : modÃ¨les prÃ©-entraÃ®nÃ©s anglais

### Data Processing
- **Pandas** : manipulation de donnÃ©es
- **Polars** : alternative haute performance (optionnel)
- **PyArrow** : format Parquet pour stockage efficace

### Visualisation
- **Matplotlib** : graphiques statiques
- **Seaborn** : visualisations statistiques
- **Plotly** : graphiques interactifs (optionnel)

### Automation
- **Makefile** : commandes automatisÃ©es
- **pytest** : tests unitaires (optionnel)

---

## ðŸš€ Lancement rapide

### Installation

```bash
# Cloner et naviguer vers le projet
cd projects/22-proces-jk-rowling/hp_nlp

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
.\venv\Scripts\activate   # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt

# TÃ©lÃ©charger le modÃ¨le spaCy
python -m spacy download en_core_web_sm
```

### ExÃ©cution via Makefile

```bash
# Option 1 : ExÃ©cuter toute la pipeline
make all

# Option 2 : ExÃ©cuter Ã©tape par Ã©tape
make ingest        # Ã‰tape 1 : Ingestion
make nlp           # Ã‰tape 2 : Pipeline NLP
make events        # Ã‰tape 3 : Extraction Ã©vÃ©nements
make viz           # Ã‰tape 4 : Visualisations
make report        # Ã‰tape 5 : GÃ©nÃ©ration rapport

# Nettoyage
make clean         # Supprime les donnÃ©es intermÃ©diaires
make clean-all     # Reset complet
```

### ExÃ©cution manuelle (Jupyter)

```bash
# Lancer Jupyter
jupyter notebook

# ExÃ©cuter les notebooks dans l'ordre :
# 1. notebooks/01_ingest_clean.ipynb
# 2. notebooks/02_nlp_pipeline.ipynb
# 3. notebooks/03_events_extraction.ipynb
# 4. notebooks/04_aggregation_viz.ipynb
# 5. notebooks/05_methods_report.ipynb
```

---

## ðŸ§ª Tests

### Test smoke (vÃ©rification basique)

```bash
bash tests/test_smoke.sh
```

VÃ©rifie :
- âœ… Structure des dossiers
- âœ… PrÃ©sence des notebooks
- âœ… Installation des dÃ©pendances
- âœ… AccessibilitÃ© des modÃ¨les spaCy

### Test d'intÃ©gration

```bash
bash tests/test_integration.sh
```

VÃ©rifie :
- âœ… ExÃ©cution complÃ¨te de la pipeline
- âœ… GÃ©nÃ©ration des fichiers de sortie
- âœ… ValiditÃ© des formats (Parquet, JSON, CSV)
- âœ… CohÃ©rence des statistiques

### Tests unitaires (optionnel)

```bash
pytest tests/
```

---

## ðŸ“Š RÃ©sultats attendus

### MÃ©triques extraites par livre

- **Nombre total de phrases**
- **Ã‰vÃ©nements magiques** : sorts lancÃ©s, potions, crÃ©atures
- **Dialogues** : nombre et longueur moyenne
- **EntitÃ©s nommÃ©es** : personnages, lieux, organisations
- **Batailles et duels** : frÃ©quence et intensitÃ©
- **Ã‰vÃ©nements scolaires** : cours, examens, fÃªtes

### Visualisations gÃ©nÃ©rÃ©es

1. **Ã‰volution des Ã©vÃ©nements** : courbe temporelle sur les 7 livres
2. **Statistiques normalisÃ©es** : comparaison Ã©quitable (par 1000 phrases)
3. **Heatmap des Ã©vÃ©nements** : concentration par livre et type
4. **Comparaison des dialogues** : distribution et Ã©volution

### Rapport mÃ©thodologique

Document HTML complet incluant :
- MÃ©thodologie dÃ©taillÃ©e
- RÃ©sultats chiffrÃ©s
- Graphiques interactifs
- Limites et perspectives

---

## ðŸ’¾ PRA / Backup

### StratÃ©gie de sauvegarde

1. **DonnÃ©es sources** : textes bruts versionnÃ©s (Git LFS recommandÃ©)
2. **DonnÃ©es intermÃ©diaires** : Parquet files (`.gitignore` mais sauvegarde locale)
3. **RÃ©sultats finaux** : commits rÃ©guliers dans `outputs/`
4. **Notebooks** : versionnÃ©s avec Git

### Reprise aprÃ¨s incident

```bash
# Restaurer l'environnement
make setup

# Relancer depuis une Ã©tape spÃ©cifique
make nlp     # Si ingestion OK mais NLP Ã©chouÃ©
make viz     # Si Ã©vÃ©nements OK mais visualisations manquantes

# VÃ©rifier l'intÃ©gritÃ© des donnÃ©es
make validate
```

### Checkpoints

La pipeline crÃ©e des checkpoints automatiques :
- AprÃ¨s chaque notebook â†’ fichier `.parquet` correspondant
- MÃ©tadonnÃ©es dans `data/book_metadata.json`
- Logs d'exÃ©cution dans `notebooks/.logs/` (optionnel)

---

## ðŸ§  Notes & Retours

### âœ… Points forts

1. **Approche neuronal** : remplacement rÃ©ussi des regex par spaCy NER
2. **ReproductibilitÃ©** : notebooks Jupyter + Makefile = pipeline claire
3. **Performance** : format Parquet pour donnÃ©es volumineuses
4. **Visualisations** : insights narratifs exploitables
5. **Documentation** : mÃ©thodologie transparente et traÃ§able

### âš ï¸ Limites identifiÃ©es

1. **ModÃ¨le gÃ©nÃ©rique** : spaCy `en_core_web_sm` pas spÃ©cialisÃ© HP
   - **AmÃ©lioration possible** : fine-tuning sur corpus Harry Potter
2. **Contexte narratif** : dÃ©tection d'Ã©vÃ©nements simple
   - **AmÃ©lioration possible** : analyse de corÃ©fÃ©rence, graphes de connaissances
3. **Temps d'exÃ©cution** : ~15-30 min pour les 7 livres
   - **AmÃ©lioration possible** : parallÃ©lisation, cache intelligent

### ðŸš€ Perspectives d'amÃ©lioration

#### Court terme
- [ ] Ajouter dÃ©tection de sentiments (sentiment analysis)
- [ ] CrÃ©er timeline interactive des Ã©vÃ©nements
- [ ] Export en base de donnÃ©es (SQLite/PostgreSQL)

#### Moyen terme
- [ ] Fine-tuner un modÃ¨le spaCy sur corpus HP
- [ ] Ajouter analyse de network des personnages
- [ ] CrÃ©er API REST pour requÃªtes en temps rÃ©el

#### Long terme
- [ ] Migration vers Transformers (BERT, RoBERTa)
- [ ] GÃ©nÃ©ration de rÃ©sumÃ©s automatiques par chapitre
- [ ] Chatbot Q&A sur l'univers Harry Potter

### ðŸ“ Retours pÃ©dagogiques

**Ce qui a bien fonctionnÃ© :**
- Structure modulaire en notebooks facilitant le debug
- Documentation inline dans les notebooks
- Approche itÃ©rative : test rapide â†’ optimisation

**Ce qui pourrait Ãªtre amÃ©liorÃ© :**
- Plus de tests unitaires sur les fonctions d'extraction
- Dashboard interactif (Streamlit/Dash)
- Containerisation Docker pour isoler l'environnement

---

## ðŸ“š RÃ©fÃ©rences

### Documentation technique
- [spaCy Documentation](https://spacy.io/api/doc)
- [Named Entity Recognition Guide](https://spacy.io/usage/linguistic-features#named-entities)
- [Parquet Format Specification](https://parquet.apache.org/docs/)

### Ressources acadÃ©miques
- Manning, C. D., & SchÃ¼tze, H. (1999). *Foundations of Statistical Natural Language Processing*
- Jurafsky, D., & Martin, J. H. (2023). *Speech and Language Processing* (3rd ed.)

### Projets similaires
- [Harry Potter Corpus Analysis](https://github.com/efekarakus/potter-corpus)
- [Narrative Analysis with NLP](https://github.com/dhalperi/narrative-nlp)

---

## ðŸŽ“ CritÃ¨res d'acceptation

| CritÃ¨re | Statut | Notes |
|---------|--------|-------|
| Pipeline complÃ¨te exÃ©cutable | âœ… | Makefile + notebooks |
| Extraction d'au moins 4 types d'Ã©vÃ©nements | âœ… | Sorts, dialogues, batailles, scolaire |
| Visualisations claires et exploitables | âœ… | 4+ graphiques gÃ©nÃ©rÃ©s |
| Rapport mÃ©thodologique automatique | âœ… | HTML + summary.md |
| Documentation complÃ¨te | âœ… | README + ce rendu |
| Tests automatisÃ©s | âœ… | Smoke + integration |
| Code reproductible | âœ… | requirements.txt + setup |

---

## ðŸ“ž Contact & Support

**Projet :** LE PROCÃˆS DE J.K. ROWLING  
**DÃ©fi :** #22 - Workshop Poudlard EPSI  
**Date :** Octobre 2025  

Pour toute question :
1. Consulter `README.md` et `QUICKSTART.md`
2. VÃ©rifier `METHODOLOGY.md` pour dÃ©tails techniques
3. Consulter `docs/prompts_used.md` pour historique IA

---

> ðŸ§™â€â™‚ï¸ *"Les donnÃ©es ne mentent jamais, mais il faut savoir les interroger avec les bons sorts."*  
> â€” Hermione Granger, experte en NLP magique
